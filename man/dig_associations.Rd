% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dig_associations.R
\name{dig_associations}
\alias{dig_associations}
\title{Search for association rules}
\usage{
dig_associations(
  x,
  antecedent = everything(),
  consequent = everything(),
  disjoint = var_names(colnames(x)),
  excluded = NULL,
  min_length = 0L,
  max_length = Inf,
  min_coverage = 0,
  min_support = 0,
  min_confidence = 0,
  contingency_table = FALSE,
  measures = NULL,
  tautology_limit = NULL,
  t_norm = "goguen",
  max_results = Inf,
  verbose = FALSE,
  threads = 1
)
}
\arguments{
\item{x}{a matrix or data frame with data to search in. The matrix must be
numeric (double) or logical. If \code{x} is a data frame then each column
must be either numeric (double) or logical.}

\item{antecedent}{a tidyselect expression (see
\href{https://tidyselect.r-lib.org/articles/syntax.html}{tidyselect syntax})
specifying the columns to use in the antecedent (left) part of the rules}

\item{consequent}{a tidyselect expression (see
\href{https://tidyselect.r-lib.org/articles/syntax.html}{tidyselect syntax})
specifying the columns to use in the consequent (right) part of the rules}

\item{disjoint}{an atomic vector of size equal to the number of columns of \code{x}
that specifies the groups of predicates: if some elements of the \code{disjoint}
vector are equal, then the corresponding columns of \code{x} will NOT be
present together in a single condition. If \code{x} is prepared with
\code{\link[=partition]{partition()}}, using the \code{\link[=var_names]{var_names()}} function on \code{x}'s column names
is a convenient way to create the \code{disjoint} vector.}

\item{excluded}{NULL or a list of character vectors, where each character vector
contains the names of columns that must not appear together in a single
antecedent.}

\item{min_length}{the minimum length, i.e., the minimum number of predicates in the
antecedent, of a rule to be generated. Value must be greater or equal to 0.
If 0, rules with empty antecedent are generated in the first place.}

\item{max_length}{The maximum length, i.e., the maximum number of predicates in the
antecedent, of a rule to be generated. If equal to Inf, the maximum length
is limited only by the number of available predicates.}

\item{min_coverage}{the minimum coverage of a rule in the dataset \code{x}.
(See Description for the definition of \emph{coverage}.)}

\item{min_support}{the minimum support of a rule in the dataset \code{x}.
(See Description for the definition of \emph{support}.)}

\item{min_confidence}{the minimum confidence of a rule in the dataset \code{x}.
(See Description for the definition of \emph{confidence}.)}

\item{contingency_table}{a logical value indicating whether to provide a contingency
table for each rule. If \code{TRUE}, the columns \code{pp}, \code{pn}, \code{np}, and \code{nn} are
added to the output table. These columns contain the number of rows satisfying
the antecedent and the consequent, the antecedent but not the consequent,
the consequent but not the antecedent, and neither the antecedent nor the
consequent, respectively.}

\item{measures}{a character vector specifying the additional quality measures to compute.
If \code{NULL}, no additional measures are computed. Possible values are \code{"lift"},
\code{"conviction"}, \code{"added_value"}.
See \url{https://mhahsler.github.io/arules/docs/measures}
for a description of the measures.}

\item{tautology_limit}{a numeric scalar (experimental feature)}

\item{t_norm}{a t-norm used to compute conjunction of weights. It must be one of
\code{"goedel"} (minimum t-norm), \code{"goguen"} (product t-norm), or \code{"lukas"}
(Lukasiewicz t-norm).}

\item{max_results}{the maximum number of generated conditions to execute the
callback function on. If the number of found conditions exceeds
\code{max_results}, the function stops generating new conditions and returns
the results. To avoid long computations during the search, it is recommended
to set \code{max_results} to a reasonable positive value. Setting \code{max_results}
to \code{Inf} will generate all possible conditions.}

\item{verbose}{a logical value indicating whether to print progress messages.}

\item{threads}{the number of threads to use for parallel computation.}
}
\value{
A tibble with found patterns and computed quality measures.
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}

Association rules identify conditions (\emph{antecedents}) under which
a specific feature (\emph{consequent}) is present very often.

\describe{
\item{Scheme:}{\verb{A => C}\cr\cr
If condition \code{A} is satisfied, then the feature \code{C} is present very often.}
\item{Example:}{\verb{university_edu & middle_age & IT_industry => high_income}\cr\cr
People in \emph{middle age} with \emph{university education} working in IT industry
have very likely a \emph{high income}.}
}

Antecedent \code{A} is usually a set of predicates, and consequent \code{C} is a single
predicate.

For the following explanations we need a mathematical function \eqn{supp(I)}, which
is defined for a set \eqn{I} of predicates as a relative frequency of rows satisfying
all predicates from \eqn{I}. For logical data, \eqn{supp(I)} equals to the relative
frequency of rows, for which all predicates \eqn{i_1, i_2, \ldots, i_n} from \eqn{I} are TRUE.
For numerical (double) input, \eqn{supp(I)} is computed as the mean (over all rows)
of truth degrees of the formula \verb{i_1 AND i_2 AND ... AND i_n}, where
\code{AND} is a triangular norm selected by the \code{t_norm} argument.

Association rules are characterized with the following quality measures.

\emph{Length} of a rule is the number of elements in the antecedent.

\emph{Coverage} of a rule is equal to \eqn{supp(A)}.

\emph{Consequent support} of a rule is equal to \eqn{supp(\{c\})}.

\emph{Support} of a rule is equal to \eqn{supp(A \cup \{c\})}.

\emph{Confidence} of a rule is the fraction \eqn{supp(A) / supp(A \cup \{c\})}.
}
\examples{
d <- partition(mtcars, .breaks = 2)
dig_associations(d,
                 antecedent = !starts_with("mpg"),
                 consequent = starts_with("mpg"),
                 min_support = 0.3,
                 min_confidence = 0.8,
                 measures = c("lift", "conviction"))
}
\seealso{
\code{\link[=partition]{partition()}}, \code{\link[=var_names]{var_names()}}, \code{\link[=dig]{dig()}}
}
\author{
Michal Burda
}

[{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://beerda.github.io/nuggets/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://beerda.github.io/nuggets/articles/nuggets.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"nuggets: Get Started","text":"Package nuggets searches patterns can described formulae form elementary conjunctions, called conditions text. conditions constructed predicates, represent data columns. user may select interpretation conditions selecting underlying logic: crisp (.e. Boolean, binary) logic, predicate may either true (1) false (0), truth value condition computed using laws classical Boolean algebra; fuzzy logic, predicate may assigned truth degree interval \\([0, 1]\\) truth degree conjunction computed selected triangular norm (t-norm). Package nuggets allows work three common t-norms: Goedel (minimum), Goguen (product), Lukasiewicz. Let \\(, b \\[0, 1]\\) truth degrees two predicates. Goedel t-norm defined \\(\\min(, b)\\), Goguen t-norm \\(\\cdot b\\), Lukasiewicz t-norm \\(\\max(0, + b - 1)\\). analyzed nuggets, data columns serve predicates conditions either dichotomized transformed fuzzy sets. package provides functions transformations. See section Data Preparation details. nuggets provides functions search patterns pre-defined types, dig_associations() association rules, dig_paired_baseline_contrasts() contrast patterns paired numeric variables, dig_correlations() conditional correlations. See section Pre-defined Patterns details. user may also define custom function evaluate conditions search patterns different type. dig() function general function allows search patterns type. dig_grid() function wrapper around dig() allows search patterns defined conditions pair columns, whose combination evaluated user-defined function. See section Custom Patterns details.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/articles/nuggets.html","id":"preparations-of-crisp-boolean-predicates","dir":"Articles","previous_headings":"Data Preparation","what":"Preparations of Crisp (Boolean) Predicates","title":"nuggets: Get Started","text":"patterns based crisp conditions, data columns serve predicates conditions transformed logical (TRUE/FALSE) data: numeric columns transformed factors selected number levels; factors transformed dummy logical columns. operations can done help partition() function. partition() function requires dataset first argument tidyselect selection expression select columns transformed. Factors logical columns transformed dummy logical columns. numeric columns, partition() function requires .method argument specify method partitioning. \"crisp\" method divides range values selected columns intervals specified .breaks argument codes values dummy logical columns. .breaks argument numeric vector specifies border values intervals. example, consider CO2 dataset datasets package: Plant, Type, Treatment columns factors transformed dummy logical columns without special arguments added partition() function: conc uptake columns numeric. instance, can split conc column four intervals: (-Inf, 175], (175, 350], (350, 675], (675, Inf). breaks thus c(-Inf, 175, 350, 675, Inf). Similarly, can split uptake column three intervals: (-Inf, 10], (10, 20], (20, Inf) specifying breaks c(-Inf, 10, 20, Inf). transformation whole CO2 dataset crisp predicates can done follows: call partition() function returns tibble data frame selected columns transformed dummy logical columns columns remain unchanged. original factor column became replaced set logical columns, start original column name followed factor level name. example, Type column, factor two levels Quebec Mississippi, replaced two logical columns: Type=Quebec Type=Mississippi. Numeric columns replaced logical columns names indicate interval original value belongs. example, conc column replaced four logical columns: conc=(-Inf,175], conc=(175,350], conc=(350,675], conc=(675,Inf). columns transformed similarly: Now columns logical can used predicates crisp conditions.","code":"head(CO2) #>   Plant   Type  Treatment conc uptake #> 1   Qn1 Quebec nonchilled   95   16.0 #> 2   Qn1 Quebec nonchilled  175   30.4 #> 3   Qn1 Quebec nonchilled  250   34.8 #> 4   Qn1 Quebec nonchilled  350   37.2 #> 5   Qn1 Quebec nonchilled  500   35.3 #> 6   Qn1 Quebec nonchilled  675   39.2 partition(CO2, Plant:Treatment) #> # A tibble: 84 × 18 #>     conc uptake `Plant=Qn1` `Plant=Qn2` `Plant=Qn3` `Plant=Qc1` `Plant=Qc3` #>    <dbl>  <dbl> <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       #>  1    95   16   TRUE        FALSE       FALSE       FALSE       FALSE       #>  2   175   30.4 TRUE        FALSE       FALSE       FALSE       FALSE       #>  3   250   34.8 TRUE        FALSE       FALSE       FALSE       FALSE       #>  4   350   37.2 TRUE        FALSE       FALSE       FALSE       FALSE       #>  5   500   35.3 TRUE        FALSE       FALSE       FALSE       FALSE       #>  6   675   39.2 TRUE        FALSE       FALSE       FALSE       FALSE       #>  7  1000   39.7 TRUE        FALSE       FALSE       FALSE       FALSE       #>  8    95   13.6 FALSE       TRUE        FALSE       FALSE       FALSE       #>  9   175   27.3 FALSE       TRUE        FALSE       FALSE       FALSE       #> 10   250   37.1 FALSE       TRUE        FALSE       FALSE       FALSE       #> # ℹ 74 more rows #> # ℹ 11 more variables: `Plant=Qc2` <lgl>, `Plant=Mn3` <lgl>, `Plant=Mn2` <lgl>, #> #   `Plant=Mn1` <lgl>, `Plant=Mc2` <lgl>, `Plant=Mc3` <lgl>, `Plant=Mc1` <lgl>, #> #   `Type=Quebec` <lgl>, `Type=Mississippi` <lgl>, #> #   `Treatment=nonchilled` <lgl>, `Treatment=chilled` <lgl> partition(CO2, conc, .method = \"crisp\", .breaks = c(-Inf, 175, 350, 675, Inf)) #> # A tibble: 84 × 8 #>    Plant Type   Treatment  uptake `conc=(-Inf;175]` `conc=(175;350]` #>    <ord> <fct>  <fct>       <dbl> <lgl>             <lgl>            #>  1 Qn1   Quebec nonchilled   16   TRUE              FALSE            #>  2 Qn1   Quebec nonchilled   30.4 TRUE              FALSE            #>  3 Qn1   Quebec nonchilled   34.8 FALSE             TRUE             #>  4 Qn1   Quebec nonchilled   37.2 FALSE             TRUE             #>  5 Qn1   Quebec nonchilled   35.3 FALSE             FALSE            #>  6 Qn1   Quebec nonchilled   39.2 FALSE             FALSE            #>  7 Qn1   Quebec nonchilled   39.7 FALSE             FALSE            #>  8 Qn2   Quebec nonchilled   13.6 TRUE              FALSE            #>  9 Qn2   Quebec nonchilled   27.3 TRUE              FALSE            #> 10 Qn2   Quebec nonchilled   37.1 FALSE             TRUE             #> # ℹ 74 more rows #> # ℹ 2 more variables: `conc=(350;675]` <lgl>, `conc=(675;Inf]` <lgl> crispCO2 <- CO2 |>     partition(Plant:Treatment) |>     partition(conc, .method = \"crisp\", .breaks = c(-Inf, 175, 350, 675, Inf)) |>     partition(uptake, .method = \"crisp\", .breaks = c(-Inf, 10, 20, Inf))  head(crispCO2) #> # A tibble: 6 × 23 #>   `Plant=Qn1` `Plant=Qn2` `Plant=Qn3` `Plant=Qc1` `Plant=Qc3` `Plant=Qc2` #>   <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       #> 1 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 2 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 3 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 4 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 5 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 6 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> # ℹ 17 more variables: `Plant=Mn3` <lgl>, `Plant=Mn2` <lgl>, `Plant=Mn1` <lgl>, #> #   `Plant=Mc2` <lgl>, `Plant=Mc3` <lgl>, `Plant=Mc1` <lgl>, #> #   `Type=Quebec` <lgl>, `Type=Mississippi` <lgl>, #> #   `Treatment=nonchilled` <lgl>, `Treatment=chilled` <lgl>, #> #   `conc=(-Inf;175]` <lgl>, `conc=(175;350]` <lgl>, `conc=(350;675]` <lgl>, #> #   `conc=(675;Inf]` <lgl>, `uptake=(-Inf;10]` <lgl>, `uptake=(10;20]` <lgl>, #> #   `uptake=(20;Inf]` <lgl> colnames(crispCO2) #>  [1] \"Plant=Qn1\"            \"Plant=Qn2\"            \"Plant=Qn3\"            #>  [4] \"Plant=Qc1\"            \"Plant=Qc3\"            \"Plant=Qc2\"            #>  [7] \"Plant=Mn3\"            \"Plant=Mn2\"            \"Plant=Mn1\"            #> [10] \"Plant=Mc2\"            \"Plant=Mc3\"            \"Plant=Mc1\"            #> [13] \"Type=Quebec\"          \"Type=Mississippi\"     \"Treatment=nonchilled\" #> [16] \"Treatment=chilled\"    \"conc=(-Inf;175]\"      \"conc=(175;350]\"       #> [19] \"conc=(350;675]\"       \"conc=(675;Inf]\"       \"uptake=(-Inf;10]\"     #> [22] \"uptake=(10;20]\"       \"uptake=(20;Inf]\""},{"path":"https://beerda.github.io/nuggets/articles/nuggets.html","id":"preparations-of-fuzzy-predicates","dir":"Articles","previous_headings":"Data Preparation","what":"Preparations of Fuzzy Predicates","title":"nuggets: Get Started","text":"patterns based fuzzy conditions, data columns serve predicates conditions transformed fuzzy predicates. fuzzy predicate represented vector truth degrees interval \\([0, 1]\\). truth degree predicate degree predicate true 0 meaning predicate false 1 meaning predicate true. value 0 1 indicates partial truthfulness. order search fuzzy patterns, numeric input data columns transformed fuzzy predicates, .e., vectors truth degrees interval \\([0, 1]\\). (Fuzzy methods allow used logical columns .) transformation fuzzy predicates can done help partition() function. , factors transformed dummy logical columns. hand, numeric columns transformed fuzzy predicates. , partition() function provides two fuzzy partitioning methods: \"triangle\" \"raisedcos\". \"triangle\" method creates fuzzy sets triangular membership functions, \"raisedcos\" method creates fuzzy sets raised cosine membership functions. advanced fuzzy partitioning numeric columns may achieved help lfl package, provides tools definition fuzzy sets many types including fuzzy sets model linguistic terms “small”, “extremely big” . See lfl documentation information. following example, conc uptake columns transformed fuzzy sets triangular membership functions. , partition() function requires .breaks argument specify shape fuzzy sets. .method = \"triangle\", consecutive triplet values .breaks vector specifies single triangular fuzzy set: first last value triplet borders triangle, middle value peak triangle. instance, conc column’s .breaks may specified c(-Inf, 175, 350, 675, Inf), creates three triangular fuzzy sets: conc=(-Inf,175,350), conc=(175,350,675), conc=(350,675,Inf). Similarly, uptake column’s .breaks may specified c(-Inf, 18, 28, 37, Inf). transformation whole CO2 dataset fuzzy predicates can done follows:","code":"fuzzyCO2 <- CO2 |>     partition(Plant:Treatment) |>     partition(conc, .method = \"triangle\", .breaks = c(-Inf, 175, 350, 675, Inf)) |>     partition(uptake, .method = \"triangle\", .breaks = c(-Inf, 18, 28, 37, Inf))  head(fuzzyCO2) #> # A tibble: 6 × 22 #>   `Plant=Qn1` `Plant=Qn2` `Plant=Qn3` `Plant=Qc1` `Plant=Qc3` `Plant=Qc2` #>   <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       #> 1 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 2 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 3 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 4 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 5 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 6 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> # ℹ 16 more variables: `Plant=Mn3` <lgl>, `Plant=Mn2` <lgl>, `Plant=Mn1` <lgl>, #> #   `Plant=Mc2` <lgl>, `Plant=Mc3` <lgl>, `Plant=Mc1` <lgl>, #> #   `Type=Quebec` <lgl>, `Type=Mississippi` <lgl>, #> #   `Treatment=nonchilled` <lgl>, `Treatment=chilled` <lgl>, #> #   `conc=(-Inf;175;350)` <dbl>, `conc=(175;350;675)` <dbl>, #> #   `conc=(350;675;Inf)` <dbl>, `uptake=(-Inf;18;28)` <dbl>, #> #   `uptake=(18;28;37)` <dbl>, `uptake=(28;37;Inf)` <dbl> colnames(fuzzyCO2) #>  [1] \"Plant=Qn1\"            \"Plant=Qn2\"            \"Plant=Qn3\"            #>  [4] \"Plant=Qc1\"            \"Plant=Qc3\"            \"Plant=Qc2\"            #>  [7] \"Plant=Mn3\"            \"Plant=Mn2\"            \"Plant=Mn1\"            #> [10] \"Plant=Mc2\"            \"Plant=Mc3\"            \"Plant=Mc1\"            #> [13] \"Type=Quebec\"          \"Type=Mississippi\"     \"Treatment=nonchilled\" #> [16] \"Treatment=chilled\"    \"conc=(-Inf;175;350)\"  \"conc=(175;350;675)\"   #> [19] \"conc=(350;675;Inf)\"   \"uptake=(-Inf;18;28)\"  \"uptake=(18;28;37)\"    #> [22] \"uptake=(28;37;Inf)\""},{"path":"https://beerda.github.io/nuggets/articles/nuggets.html","id":"pre-defined-patterns","dir":"Articles","previous_headings":"","what":"Pre-defined Patterns","title":"nuggets: Get Started","text":"nuggets provides set functions searching best-known pattern types. functions allow process Boolean data, fuzzy data, . result functions always tibble patterns stored rows. advance usage, allows search custom patterns compute user-defined measures statistics, see section Custom Patterns.","code":""},{"path":"https://beerda.github.io/nuggets/articles/nuggets.html","id":"search-for-association-rules","dir":"Articles","previous_headings":"Pre-defined Patterns","what":"Search for Association Rules","title":"nuggets: Get Started","text":"Association rules rules form \\(\\Rightarrow B\\), \\(\\) either Boolean fuzzy condition form conjunction, \\(B\\) Boolean fuzzy predicate. continuing search rules, advisable create -called vector disjoints. vector disjoints character vector length number columns analyzed dataset. specifies predicates, mutually exclusive combined together single pattern’s condition: columns equal values disjoint vector appear single condition. Providing vector disjoints algorithm speed-search makes sense, e.g., combine Plant=Qn1 Plant=Qn2 condition Plant=Qn1 & Plant=Qn2 formula never true data row. vector disjoints can easily created column names dataset, e.g., obtaining first part column names equal sign, neatly provided var_names() function follows: function dig_associations takes analyzed dataset first parameter pair tidyselect expressions select column names appear left-hand (antecedent) right-hand (consequent) side rule. following command searches associations rules, : column except starting “Treatment” antecedent; column starting “Treatment” consequent; minimum support 0.02 (support proportion rows satisfy antecedent consequent)); minimum confidence 0.8 (confidence proportion rows satisfying consequent GIVEN antecedent true). result tibble found rules. may arrange support descending order:","code":"disj <- var_names(colnames(fuzzyCO2)) print(disj) #>  [1] \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     #>  [7] \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     #> [13] \"Type\"      \"Type\"      \"Treatment\" \"Treatment\" \"conc\"      \"conc\"      #> [19] \"conc\"      \"uptake\"    \"uptake\"    \"uptake\" result <- dig_associations(fuzzyCO2,                            antecedent = !starts_with(\"Treatment\"),                            consequent = starts_with(\"Treatment\"),                            disjoint = disj,                            min_support = 0.02,                            min_confidence = 0.8) result <- arrange(result, desc(support)) print(result) #> # A tibble: 188 × 8 #>    antecedent        consequent support confidence coverage conseq_support count #>    <chr>             <chr>        <dbl>      <dbl>    <dbl>          <dbl> <dbl> #>  1 {Type=Mississipp… {Treatmen…  0.135       0.895   0.151             0.5  11.4 #>  2 {Plant=Qn2}       {Treatmen…  0.0833      1       0.0833            0.5   7   #>  3 {Plant=Mc1}       {Treatmen…  0.0833      1       0.0833            0.5   7   #>  4 {Plant=Mc3}       {Treatmen…  0.0833      1       0.0833            0.5   7   #>  5 {Plant=Mc2}       {Treatmen…  0.0833      1       0.0833            0.5   7   #>  6 {Plant=Mn1}       {Treatmen…  0.0833      1       0.0833            0.5   7   #>  7 {Plant=Mn2}       {Treatmen…  0.0833      1       0.0833            0.5   7   #>  8 {Plant=Mn3}       {Treatmen…  0.0833      1       0.0833            0.5   7   #>  9 {Plant=Qc2}       {Treatmen…  0.0833      1       0.0833            0.5   7   #> 10 {Plant=Qc3}       {Treatmen…  0.0833      1       0.0833            0.5   7   #> # ℹ 178 more rows #> # ℹ 1 more variable: antecedent_length <int>"},{"path":"https://beerda.github.io/nuggets/articles/nuggets.html","id":"conditional-correlations","dir":"Articles","previous_headings":"Pre-defined Patterns","what":"Conditional Correlations","title":"nuggets: Get Started","text":"TBD (dig_correlations)","code":""},{"path":"https://beerda.github.io/nuggets/articles/nuggets.html","id":"contrast-patterns","dir":"Articles","previous_headings":"Pre-defined Patterns","what":"Contrast Patterns","title":"nuggets: Get Started","text":"TBD (dig_contrasts)","code":""},{"path":"https://beerda.github.io/nuggets/articles/nuggets.html","id":"custom-patterns","dir":"Articles","previous_headings":"","what":"Custom Patterns","title":"nuggets: Get Started","text":"nuggets package allows execute user-defined callback function generated frequent condition. way custom type patterns may searched. following example replicates search associations rules custom callback function. , dataset dichotomized disjoint vector created Data Preparation section : want search associations rules minimum support confidence, define variables hold thresholds. also need define callback function called found frequent condition. purpose generate rules obtained condition antecedent: callback function f() defines three arguments: condition, support foci_supports. names arguments random. Based argument names callback function, searching algorithm provides information function. condition vector indices representing conjunction predicates condition. predicate mean column source dataset. support argument gets relative frequency condition dataset. foci_supports vector supports special predicates, call “foci” (plural “focus”), within rows satisfying condition. associations rules, foci potential rule consequents. Now can run digging rules: return list lists callback function, flatten first level lists result binding data frame:","code":"head(fuzzyCO2) #> # A tibble: 6 × 22 #>   `Plant=Qn1` `Plant=Qn2` `Plant=Qn3` `Plant=Qc1` `Plant=Qc3` `Plant=Qc2` #>   <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       #> 1 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 2 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 3 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 4 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 5 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> 6 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #> # ℹ 16 more variables: `Plant=Mn3` <lgl>, `Plant=Mn2` <lgl>, `Plant=Mn1` <lgl>, #> #   `Plant=Mc2` <lgl>, `Plant=Mc3` <lgl>, `Plant=Mc1` <lgl>, #> #   `Type=Quebec` <lgl>, `Type=Mississippi` <lgl>, #> #   `Treatment=nonchilled` <lgl>, `Treatment=chilled` <lgl>, #> #   `conc=(-Inf;175;350)` <dbl>, `conc=(175;350;675)` <dbl>, #> #   `conc=(350;675;Inf)` <dbl>, `uptake=(-Inf;18;28)` <dbl>, #> #   `uptake=(18;28;37)` <dbl>, `uptake=(28;37;Inf)` <dbl> print(disj) #>  [1] \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     #>  [7] \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     \"Plant\"     #> [13] \"Type\"      \"Type\"      \"Treatment\" \"Treatment\" \"conc\"      \"conc\"      #> [19] \"conc\"      \"uptake\"    \"uptake\"    \"uptake\" min_support <- 0.02 min_confidence <- 0.8  f <- function(condition, support, foci_supports) {     conf <- foci_supports / support     sel <- !is.na(conf) & conf >= min_confidence & !is.na(foci_supports) & foci_supports >= min_support     conf <- conf[sel]     supp <- foci_supports[sel]          lapply(seq_along(conf), function(i) {        list(antecedent = format_condition(names(condition)),            consequent = format_condition(names(conf)[[i]]),            support = supp[[i]],            confidence = conf[[i]])     }) } result <- dig(fuzzyCO2,               f = f,               condition = !starts_with(\"Treatment\"),               focus = starts_with(\"Treatment\"),               disjoint = disj,               min_length = 1,               min_support = min_support) result <- result |>   unlist(recursive = FALSE) |>   lapply(as_tibble) |>   do.call(rbind, args = _) |>   arrange(desc(support))  print(result) #> # A tibble: 188 × 4 #>    antecedent                           consequent            support confidence #>    <chr>                                <chr>                   <dbl>      <dbl> #>  1 {Type=Mississippi,uptake=(18;28;37)} {Treatment=nonchille…  0.135       0.895 #>  2 {Plant=Qn2}                          {Treatment=nonchille…  0.0833      1     #>  3 {Plant=Mc1}                          {Treatment=chilled}    0.0833      1     #>  4 {Plant=Mc3}                          {Treatment=chilled}    0.0833      1     #>  5 {Plant=Mc2}                          {Treatment=chilled}    0.0833      1     #>  6 {Plant=Mn1}                          {Treatment=nonchille…  0.0833      1     #>  7 {Plant=Mn2}                          {Treatment=nonchille…  0.0833      1     #>  8 {Plant=Mn3}                          {Treatment=nonchille…  0.0833      1     #>  9 {Plant=Qc2}                          {Treatment=chilled}    0.0833      1     #> 10 {Plant=Qc3}                          {Treatment=chilled}    0.0833      1     #> # ℹ 178 more rows"},{"path":"https://beerda.github.io/nuggets/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Michal Burda. Author, maintainer.","code":""},{"path":"https://beerda.github.io/nuggets/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Burda M (2024). “nuggets: Data Pattern Extraction Framework R.” Torra, Vicenc, Narukawa, Yasuo, Kikuchi, Hiroaki (eds.), Modeling Decisions Artificial Intelligence, 115–126. ISBN 978-3-031-68208-7, doi:10.1007/978-3-031-68208-7_10.","code":"@InProceedings{,   title = {nuggets: Data Pattern Extraction Framework in R},   author = {Michal Burda},   editor = {{Torra} and {Vicenc} and {Narukawa} and {Yasuo} and {Kikuchi} and {Hiroaki}},   booktitle = {Modeling Decisions for Artificial Intelligence},   year = {2024},   publisher = {Springer Nature Switzerland},   address = {Cham},   pages = {115--126},   isbn = {978-3-031-68208-7},   doi = {10.1007/978-3-031-68208-7_10}, }"},{"path":"https://beerda.github.io/nuggets/index.html","id":"nuggets","dir":"","previous_headings":"","what":"Extensible Data Pattern Searching Framework","title":"Extensible Data Pattern Searching Framework","text":"Extensible R framework subgroup discovery (Atzmueller (2015)), contrast patterns (Chen (2022)), emerging patterns (Dong (1999)), association rules (Agrawal (1994)), conditional correlations (Hájek (1978)). crisp (Boolean, binary) fuzzy data supported. package generates conditions form elementary conjunctions, evaluates dataset checks induced sub-data interesting statistical properties. user-defined function may defined evaluate generated condition search custom patterns.","code":""},{"path":"https://beerda.github.io/nuggets/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Extensible Data Pattern Searching Framework","text":"install stable version nuggets CRAN, type following command within R session: can also install development version nuggets GitHub : start using package, load R session :","code":"install.packages(\"nuggets\") install.packages(\"devtools\") devtools::install_github(\"beerda/nuggets\") library(nuggets)"},{"path":"https://beerda.github.io/nuggets/reference/dichotomize.html","id":null,"dir":"Reference","previous_headings":"","what":"Create dummy columns from logicals or factors in a data frame — dichotomize","title":"Create dummy columns from logicals or factors in a data frame — dichotomize","text":"function deprecated partition() general can used create dummy columns well. Create dummy logical columns selected columns data frame. Dummy columns may created logical factor columns follows: logical column col, pair columns created named col=T col=F former (resp. latter) equal original (resp. negation original); factor column col, new logical column created level l factor col named col=l value set TRUE wherever original column equal l.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dichotomize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create dummy columns from logicals or factors in a data frame — dichotomize","text":"","code":"dichotomize(.data, what = everything(), ..., .keep = FALSE, .other = FALSE)"},{"path":"https://beerda.github.io/nuggets/reference/dichotomize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create dummy columns from logicals or factors in a data frame — dichotomize","text":".data data frame processed tidyselect expression (see tidyselect syntax) selecting columns processed ... tidyselect expressions selecting columns processed .keep whether keep original columns. FALSE, original columns removed result. .whether put result rest columns specified dichotomization argument.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dichotomize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create dummy columns from logicals or factors in a data frame — dichotomize","text":"tibble selected columns replaced dummy columns.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dichotomize.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create dummy columns from logicals or factors in a data frame — dichotomize","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dichotomize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create dummy columns from logicals or factors in a data frame — dichotomize","text":"","code":"dichotomize(CO2, Plant:Treatment, .other = TRUE) #> Warning: `dichotomize()` was deprecated in nuggets 1.4.0. #> ℹ Please use `partition()` instead. #> # A tibble: 84 × 18 #>     conc uptake `Plant=Qn1` `Plant=Qn2` `Plant=Qn3` `Plant=Qc1` `Plant=Qc3` #>    <dbl>  <dbl> <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       #>  1    95   16   TRUE        FALSE       FALSE       FALSE       FALSE       #>  2   175   30.4 TRUE        FALSE       FALSE       FALSE       FALSE       #>  3   250   34.8 TRUE        FALSE       FALSE       FALSE       FALSE       #>  4   350   37.2 TRUE        FALSE       FALSE       FALSE       FALSE       #>  5   500   35.3 TRUE        FALSE       FALSE       FALSE       FALSE       #>  6   675   39.2 TRUE        FALSE       FALSE       FALSE       FALSE       #>  7  1000   39.7 TRUE        FALSE       FALSE       FALSE       FALSE       #>  8    95   13.6 FALSE       TRUE        FALSE       FALSE       FALSE       #>  9   175   27.3 FALSE       TRUE        FALSE       FALSE       FALSE       #> 10   250   37.1 FALSE       TRUE        FALSE       FALSE       FALSE       #> # ℹ 74 more rows #> # ℹ 11 more variables: `Plant=Qc2` <lgl>, `Plant=Mn3` <lgl>, `Plant=Mn2` <lgl>, #> #   `Plant=Mn1` <lgl>, `Plant=Mc2` <lgl>, `Plant=Mc3` <lgl>, `Plant=Mc1` <lgl>, #> #   `Type=Quebec` <lgl>, `Type=Mississippi` <lgl>, #> #   `Treatment=nonchilled` <lgl>, `Treatment=chilled` <lgl> # -> partition(CO2, Plant:Treatment) #> # A tibble: 84 × 18 #>     conc uptake `Plant=Qn1` `Plant=Qn2` `Plant=Qn3` `Plant=Qc1` `Plant=Qc3` #>    <dbl>  <dbl> <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       #>  1    95   16   TRUE        FALSE       FALSE       FALSE       FALSE       #>  2   175   30.4 TRUE        FALSE       FALSE       FALSE       FALSE       #>  3   250   34.8 TRUE        FALSE       FALSE       FALSE       FALSE       #>  4   350   37.2 TRUE        FALSE       FALSE       FALSE       FALSE       #>  5   500   35.3 TRUE        FALSE       FALSE       FALSE       FALSE       #>  6   675   39.2 TRUE        FALSE       FALSE       FALSE       FALSE       #>  7  1000   39.7 TRUE        FALSE       FALSE       FALSE       FALSE       #>  8    95   13.6 FALSE       TRUE        FALSE       FALSE       FALSE       #>  9   175   27.3 FALSE       TRUE        FALSE       FALSE       FALSE       #> 10   250   37.1 FALSE       TRUE        FALSE       FALSE       FALSE       #> # ℹ 74 more rows #> # ℹ 11 more variables: `Plant=Qc2` <lgl>, `Plant=Mn3` <lgl>, `Plant=Mn2` <lgl>, #> #   `Plant=Mn1` <lgl>, `Plant=Mc2` <lgl>, `Plant=Mc3` <lgl>, `Plant=Mc1` <lgl>, #> #   `Type=Quebec` <lgl>, `Type=Mississippi` <lgl>, #> #   `Treatment=nonchilled` <lgl>, `Treatment=chilled` <lgl>"},{"path":"https://beerda.github.io/nuggets/reference/dig.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for patterns of custom type — dig","title":"Search for patterns of custom type — dig","text":"general function searching patterns custom type. function allows selection columns x used condition predicates. function enumerates possible conditions form elementary conjunctions selected predicates, condition, user-defined callback function f executed. callback function intended perform analysis return object representing pattern patterns related condition. dig() returns list returned objects. callback function f may arguments listed f argument description. algorithm provides information generated condition based present arguments. Additionally condition, function allows selection -called focus predicates. focus predicates, .k.. foci, predicates evaluated within condition additional information provided callback function . dig() allows specify restrictions generated conditions, : minimum maximum length condition (min_length max_length arguments). minimum support condition (min_support argument). Support condition relative frequency condition dataset x. minimum support focus (min_focus_support argument). Support focus relative frequency rows condition predicates focus TRUE . Foci support lower min_focus_support filtered .","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for patterns of custom type — dig","text":"","code":"dig(   x,   f,   condition = everything(),   focus = NULL,   disjoint = var_names(colnames(x)),   excluded = NULL,   min_length = 0,   max_length = Inf,   min_support = 0,   min_focus_support = 0,   min_conditional_focus_support = 0,   max_support = 1,   filter_empty_foci = FALSE,   tautology_limit = NULL,   t_norm = \"goguen\",   max_results = Inf,   verbose = FALSE,   threads = 1L,   error_context = list(arg_x = \"x\", arg_f = \"f\", arg_condition = \"condition\", arg_focus =     \"focus\", arg_disjoint = \"disjoint\", arg_excluded = \"excluded\", arg_min_length =     \"min_length\", arg_max_length = \"max_length\", arg_min_support = \"min_support\",     arg_min_focus_support = \"min_focus_support\", arg_min_conditional_focus_support =     \"min_conditional_focus_support\", arg_max_support = \"max_support\",     arg_filter_empty_foci = \"filter_empty_foci\", arg_tautology_limit = \"tautology_limit\",     arg_t_norm = \"t_norm\", arg_max_results = \"max_results\",       arg_verbose =     \"verbose\", arg_threads = \"threads\", call = current_env()) )"},{"path":"https://beerda.github.io/nuggets/reference/dig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for patterns of custom type — dig","text":"x matrix data frame. matrix must numeric (double) logical. x data frame column must either numeric (double) logical. f callback function executed generated condition. function may following arguments. Based present arguments, algorithm provide information generated condition: condition - named integer vector column indices represent predicates condition. Names vector correspond column names; support - numeric scalar value current condition's support; indices - logical vector indicating rows satisfying condition; weights - (similar indices) weights rows satisfy current condition; pp - value contingency table, condition & focus. pp named numeric vector value support conjunction condition foci column (see focus argument specify, columns). Names vector foci column names. pn - value contingency table, condition & neg focus. pn named numeric vector value support conjunction condition negated foci column (see focus argument specify, columns foci) - names vector foci column names. np - value contingency table, neg condition & focus. np named numeric vector value support conjunction negated condition foci column (see focus argument specify, columns foci) - names vector foci column names. nn - value contingency table, neg condition & neg focus. nn named numeric vector value support conjunction negated condition negated foci column (see focus argument specify, columns foci) - names vector foci column names. foci_supports - (deprecated, use pp instead) named numeric vector supports foci columns (see focus argument specify, columns foci) - names vector foci column names. condition tidyselect expression (see tidyselect syntax) specifying columns use condition predicates focus tidyselect expression (see tidyselect syntax) specifying columns use focus predicates disjoint atomic vector size equal number columns x specifies groups predicates: elements disjoint vector equal, corresponding columns x present together single condition. x prepared partition(), using var_names() function x's column names convenient way create disjoint vector. excluded NULL list character vectors, character vector represents formula form implication, last element antecedent last element consequent. formulae treated tautologies serve purpose filtering generated conditions. generated condition contains antecedent consequent formulae, condition passed callback function f. Similarly, generated condition contains antecedent formulae, focus, consequent formula, passed callback function f. min_length minimum size (minimum number predicates) condition trigger callback function f. value argument must greater equal 0. 0, also empty condition triggers callback. max_length maximum allowed size (maximum number predicates) condition. Conditions longer max_length generated. equal Inf, maximum length conditions limited number available predicates. value argument must greater equal 0 also greater equal min_length. argument effectively affects speed search process number triggered calls callback function f. min_support minimum support condition trigger callback function f. support condition relative frequency condition dataset x. logical data, equals relative frequency rows condition predicates TRUE . numerical (double) input, support computed mean (rows) multiplications predicate values. value argument must range \\([0, 1]\\). support condition lower min_support, recursive search conditions containing current condition stopped. Therefore, value min_support effectively affects speed search process number triggered calls callback function f. min_focus_support minimum required support focus, passed callback function f. support focus relative frequency rows condition predicates focus TRUE . logical data, equals relative frequency rows, condition predicates focus TRUE. numerical (double) input treated membership degrees fuzzy sets support computed mean (rows) t-norm predicate values. (applied t-norm selected t_norm argument, see .) value argument must range \\([0, 1]\\). support focus lower min_focus_support, focus passed callback function f. See also filter_empty_foci argument , together min_focus_support, effectively affects speed search process number triggered calls callback function f. min_conditional_focus_support minimum relative support focus within condition. conditional support focus relative frequency rows focus TRUE within rows condition TRUE. \\(s(C)\\) represents relative frequency condition TRUE within dataset \\(s(C \\cup F)\\) represents relative frequency condition focus TRUE within dataset, (computed t-norm input numerical), conditional support focus \\(s(C \\cup F) / s(C)\\). value argument must range \\([0, 1]\\). conditional support focus lower min_conditional_focus_support, focus passed callback function f. See also filter_empty_foci argument , together min_conditional_focus_support, effectively affects speed search process number triggered calls callback function f. max_support maximum support condition trigger callback function f. support condition greater max_support, condition passed callback function. max_support stop recursive generation conditions containing current condition, execution callback function. value argument must range \\([0, 1]\\). filter_empty_foci logical scalar indicating whether skip triggering callback function f conditions, focus remains available filtering min_focus_support min_conditional_focus_support. TRUE, callback function f triggered least one focus remains filtering. FALSE, callback function f triggered regardless number remaining foci. tautology_limit numeric scalar (experimental feature) t_norm t-norm used compute conjunction weights. must one \"goedel\" (minimum t-norm), \"goguen\" (product t-norm), \"lukas\" (Lukasiewicz t-norm). max_results maximum number generated conditions execute callback function . number found conditions exceeds max_results, function stops generating new conditions returns results. avoid long computations search, recommended set max_results reasonable positive value. Setting max_results Inf generate possible conditions. verbose logical scalar indicating whether print progress messages. threads number threads use parallel computation. error_context list details used error messages. argument useful dig() called another function provide error messages, refer arguments calling function. list must contain following elements: arg_x - name argument x character string arg_f - name argument f character string arg_condition - name argument condition character string arg_focus - name argument focus character string arg_disjoint - name argument disjoint character string arg_excluded - name argument excluded character string arg_min_length - name argument min_length character string arg_max_length - name argument max_length character string arg_min_support - name argument min_support character string arg_min_focus_support - name argument min_focus_support character string arg_min_conditional_focus_support - name argument min_conditional_focus_support character string arg_max_support - name argument max_support character arg_filter_empty_foci - name argument filter_empty_foci character string arg_t_norm - name argument t_norm character string arg_threads - name argument threads character string call - environment evaluate error messages.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for patterns of custom type — dig","text":"list results provided callback function f.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for patterns of custom type — dig","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for patterns of custom type — dig","text":"","code":"library(tibble)  # Prepare iris data for use with dig() d <- partition(iris, .breaks = 2)  # Call f() for each condition with support >= 0.5. The result is a list # of strings representing the conditions. dig(x = d,     f = function(condition) {         format_condition(names(condition))     },     min_support = 0.5) #> [[1]] #> [1] \"{}\" #>  #> [[2]] #> [1] \"{Petal.Width=(-Inf;1.3]}\" #>  #> [[3]] #> [1] \"{Petal.Length=(3.95;Inf]}\" #>  #> [[4]] #> [1] \"{Sepal.Length=(-Inf;6.1]}\" #>  #> [[5]] #> [1] \"{Sepal.Width=(-Inf;3.2]}\" #>  #> [[6]] #> [1] \"{Petal.Length=(3.95;Inf],Sepal.Width=(-Inf;3.2]}\" #>   # Create a more complex pattern object - a list with some statistics res <- dig(x = d,            f = function(condition, support) {                list(condition = format_condition(names(condition)),                     support = support)            },            min_support = 0.5) print(res) #> [[1]] #> [[1]]$condition #> [1] \"{}\" #>  #> [[1]]$support #> [1] 1 #>  #>  #> [[2]] #> [[2]]$condition #> [1] \"{Petal.Width=(-Inf;1.3]}\" #>  #> [[2]]$support #> [1] 0.52 #>  #>  #> [[3]] #> [[3]]$condition #> [1] \"{Petal.Length=(3.95;Inf]}\" #>  #> [[3]]$support #> [1] 0.5933333 #>  #>  #> [[4]] #> [[4]]$condition #> [1] \"{Sepal.Length=(-Inf;6.1]}\" #>  #> [[4]]$support #> [1] 0.6333333 #>  #>  #> [[5]] #> [[5]]$condition #> [1] \"{Sepal.Width=(-Inf;3.2]}\" #>  #> [[5]]$support #> [1] 0.7133333 #>  #>  #> [[6]] #> [[6]]$condition #> [1] \"{Petal.Length=(3.95;Inf],Sepal.Width=(-Inf;3.2]}\" #>  #> [[6]]$support #> [1] 0.5266666 #>  #>   # Format the result as a data frame do.call(rbind, lapply(res, as_tibble)) #> # A tibble: 6 × 2 #>   condition                                        support #>   <chr>                                              <dbl> #> 1 {}                                                 1     #> 2 {Petal.Width=(-Inf;1.3]}                           0.520 #> 3 {Petal.Length=(3.95;Inf]}                          0.593 #> 4 {Sepal.Length=(-Inf;6.1]}                          0.633 #> 5 {Sepal.Width=(-Inf;3.2]}                           0.713 #> 6 {Petal.Length=(3.95;Inf],Sepal.Width=(-Inf;3.2]}   0.527  # Within each condition, evaluate also supports of columns starting with # \"Species\" res <- dig(x = d,            f = function(condition, support, pp) {                c(list(condition = format_condition(names(condition))),                  list(condition_support = support),                  as.list(pp / nrow(d)))            },            condition = !starts_with(\"Species\"),            focus = starts_with(\"Species\"),            min_support = 0.5,            min_focus_support = 0)  # Format the result as a tibble do.call(rbind, lapply(res, as_tibble)) #> # A tibble: 6 × 5 #>   condition              condition_support `Species=setosa` `Species=versicolor` #>   <chr>                              <dbl>            <dbl>                <dbl> #> 1 {}                                 1                0.333                0.333 #> 2 {Petal.Width=(-Inf;1.…             0.520            0.333                0.187 #> 3 {Petal.Length=(3.95;I…             0.593            0                    0.26  #> 4 {Sepal.Length=(-Inf;6…             0.633            0.333                0.227 #> 5 {Sepal.Width=(-Inf;3.…             0.713            0.113                0.32  #> 6 {Petal.Length=(3.95;I…             0.527            0                    0.247 #> # ℹ 1 more variable: `Species=virginica` <dbl>  # For each condition, create multiple patterns based on the focus columns res <- dig(x = d,            f = function(condition, support, pp) {                lapply(seq_along(pp), function(i) {                    list(condition = format_condition(names(condition)),                         condition_support = support,                         focus = names(pp)[i],                         focus_support = pp[[i]] / nrow(d))                })            },            condition = !starts_with(\"Species\"),            focus = starts_with(\"Species\"),            min_support = 0.5,            min_focus_support = 0)  # As res is now a list of lists, we need to flatten it before converting to # a tibble res <- unlist(res, recursive = FALSE)  # Format the result as a tibble do.call(rbind, lapply(res, as_tibble)) #> # A tibble: 18 × 4 #>    condition                               condition_support focus focus_support #>    <chr>                                               <dbl> <chr>         <dbl> #>  1 {}                                                  1     Spec…        0.333  #>  2 {}                                                  1     Spec…        0.333  #>  3 {}                                                  1     Spec…        0.333  #>  4 {Petal.Width=(-Inf;1.3]}                            0.520 Spec…        0.333  #>  5 {Petal.Width=(-Inf;1.3]}                            0.520 Spec…        0.187  #>  6 {Petal.Width=(-Inf;1.3]}                            0.520 Spec…        0      #>  7 {Petal.Length=(3.95;Inf]}                           0.593 Spec…        0      #>  8 {Petal.Length=(3.95;Inf]}                           0.593 Spec…        0.26   #>  9 {Petal.Length=(3.95;Inf]}                           0.593 Spec…        0.333  #> 10 {Sepal.Length=(-Inf;6.1]}                           0.633 Spec…        0.333  #> 11 {Sepal.Length=(-Inf;6.1]}                           0.633 Spec…        0.227  #> 12 {Sepal.Length=(-Inf;6.1]}                           0.633 Spec…        0.0733 #> 13 {Sepal.Width=(-Inf;3.2]}                            0.713 Spec…        0.113  #> 14 {Sepal.Width=(-Inf;3.2]}                            0.713 Spec…        0.32   #> 15 {Sepal.Width=(-Inf;3.2]}                            0.713 Spec…        0.28   #> 16 {Petal.Length=(3.95;Inf],Sepal.Width=(…             0.527 Spec…        0      #> 17 {Petal.Length=(3.95;Inf],Sepal.Width=(…             0.527 Spec…        0.247  #> 18 {Petal.Length=(3.95;Inf],Sepal.Width=(…             0.527 Spec…        0.28"},{"path":"https://beerda.github.io/nuggets/reference/dig_associations.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for association rules — dig_associations","title":"Search for association rules — dig_associations","text":"Association rules identify conditions (antecedents) specific feature (consequent) present often. Scheme: => C condition satisfied, feature C present often. Example: university_edu & middle_age & IT_industry => high_income People middle age university education working industry likely high income. Antecedent usually set predicates, consequent C single predicate. following explanations need mathematical function \\(supp()\\), defined set \\(\\) predicates relative frequency rows satisfying predicates \\(\\). logical data, \\(supp()\\) equals relative frequency rows, predicates \\(i_1, i_2, \\ldots, i_n\\) \\(\\) TRUE. numerical (double) input, \\(supp()\\) computed mean (rows) truth degrees formula i_1 i_2 ... i_n, triangular norm selected t_norm argument. Association rules characterized following quality measures. Length rule number elements antecedent. Coverage rule equal \\(supp()\\). Consequent support rule equal \\(supp(\\{c\\})\\). Support rule equal \\(supp(\\cup \\{c\\})\\). Confidence rule fraction \\(supp() / supp(\\cup \\{c\\})\\).","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_associations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for association rules — dig_associations","text":"","code":"dig_associations(   x,   antecedent = everything(),   consequent = everything(),   disjoint = var_names(colnames(x)),   excluded = NULL,   min_length = 0L,   max_length = Inf,   min_coverage = 0,   min_support = 0,   min_confidence = 0,   contingency_table = FALSE,   measures = NULL,   tautology_limit = NULL,   t_norm = \"goguen\",   max_results = Inf,   verbose = FALSE,   threads = 1 )"},{"path":"https://beerda.github.io/nuggets/reference/dig_associations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for association rules — dig_associations","text":"x matrix data frame data search . matrix must numeric (double) logical. x data frame column must either numeric (double) logical. antecedent tidyselect expression (see tidyselect syntax) specifying columns use antecedent (left) part rules consequent tidyselect expression (see tidyselect syntax) specifying columns use consequent (right) part rules disjoint atomic vector size equal number columns x specifies groups predicates: elements disjoint vector equal, corresponding columns x present together single condition. x prepared partition(), using var_names() function x's column names convenient way create disjoint vector. excluded NULL list character vectors, character vector contains names columns must appear together single antecedent. min_length minimum length, .e., minimum number predicates antecedent, rule generated. Value must greater equal 0. 0, rules empty antecedent generated first place. max_length maximum length, .e., maximum number predicates antecedent, rule generated. equal Inf, maximum length limited number available predicates. min_coverage minimum coverage rule dataset x. (See Description definition coverage.) min_support minimum support rule dataset x. (See Description definition support.) min_confidence minimum confidence rule dataset x. (See Description definition confidence.) contingency_table logical value indicating whether provide contingency table rule. TRUE, columns pp, pn, np, nn added output table. columns contain number rows satisfying antecedent consequent, antecedent consequent, consequent antecedent, neither antecedent consequent, respectively. measures character vector specifying additional quality measures compute. NULL, additional measures computed. Possible values \"lift\", \"conviction\", \"added_value\". See https://mhahsler.github.io/arules/docs/measures description measures. tautology_limit numeric scalar (experimental feature) t_norm t-norm used compute conjunction weights. must one \"goedel\" (minimum t-norm), \"goguen\" (product t-norm), \"lukas\" (Lukasiewicz t-norm). max_results maximum number generated conditions execute callback function . number found conditions exceeds max_results, function stops generating new conditions returns results. avoid long computations search, recommended set max_results reasonable positive value. Setting max_results Inf generate possible conditions. verbose logical value indicating whether print progress messages. threads number threads use parallel computation.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_associations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for association rules — dig_associations","text":"tibble found patterns computed quality measures.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig_associations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for association rules — dig_associations","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_associations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for association rules — dig_associations","text":"","code":"d <- partition(mtcars, .breaks = 2) dig_associations(d,                  antecedent = !starts_with(\"mpg\"),                  consequent = starts_with(\"mpg\"),                  min_support = 0.3,                  min_confidence = 0.8,                  measures = c(\"lift\", \"conviction\")) #> # A tibble: 524 × 10 #>    antecedent        consequent support confidence coverage conseq_support count #>    <chr>             <chr>        <dbl>      <dbl>    <dbl>          <dbl> <dbl> #>  1 {wt=(3.47;Inf]}   {mpg=(-In…   0.344      1        0.344          0.719    11 #>  2 {cyl=(6;Inf]}     {mpg=(-In…   0.438      1        0.438          0.719    14 #>  3 {disp=(272;Inf]}  {mpg=(-In…   0.438      1        0.438          0.719    14 #>  4 {vs=(-Inf;0.5]}   {mpg=(-In…   0.531      0.944    0.562          0.719    17 #>  5 {drat=(-Inf;3.84… {mpg=(-In…   0.531      0.895    0.594          0.719    17 #>  6 {am=(-Inf;0.5]}   {mpg=(-In…   0.531      0.895    0.594          0.719    17 #>  7 {qsec=(-Inf;18.7… {mpg=(-In…   0.594      0.826    0.719          0.719    19 #>  8 {cyl=(6;Inf],wt=… {mpg=(-In…   0.344      1        0.344          0.719    11 #>  9 {disp=(272;Inf],… {mpg=(-In…   0.344      1        0.344          0.719    11 #> 10 {cyl=(6;Inf],dis… {mpg=(-In…   0.438      1        0.438          0.719    14 #> # ℹ 514 more rows #> # ℹ 3 more variables: antecedent_length <int>, lift <dbl>, conviction <dbl>"},{"path":"https://beerda.github.io/nuggets/reference/dig_baseline_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for conditions that yield in statistically significant one-sample test in selected variables. — dig_baseline_contrasts","title":"Search for conditions that yield in statistically significant one-sample test in selected variables. — dig_baseline_contrasts","text":"Baseline contrast patterns identify conditions specific feature significantly different given value performing one-sample statistical test. Scheme: var != 0 | C Variable var (average) significantly different 0 condition C. Example: (measure_error != 0 | measure_tool_A  measuring measure tool , average measure error significantly different 0. baseline contrast computed using one-sample statistical test, specified method argument. function computes contrast variables specified vars argument. Baseline contrasts computed sub-data corresponding conditions generated condition columns. Function dig_baseline_contrasts() supports crisp conditions , .e., condition columns x must logical.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_baseline_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for conditions that yield in statistically significant one-sample test in selected variables. — dig_baseline_contrasts","text":"","code":"dig_baseline_contrasts(   x,   condition = where(is.logical),   vars = where(is.numeric),   disjoint = var_names(colnames(x)),   excluded = NULL,   min_length = 0L,   max_length = Inf,   min_support = 0,   max_support = 1,   method = \"t\",   alternative = \"two.sided\",   h0 = 0,   conf_level = 0.95,   max_p_value = 0.05,   wilcox_exact = FALSE,   wilcox_correct = TRUE,   wilcox_tol_root = 1e-04,   wilcox_digits_rank = Inf,   max_results = Inf,   verbose = FALSE,   threads = 1 )"},{"path":"https://beerda.github.io/nuggets/reference/dig_baseline_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for conditions that yield in statistically significant one-sample test in selected variables. — dig_baseline_contrasts","text":"x matrix data frame data search patterns . condition tidyselect expression (see tidyselect syntax) specifying columns use condition predicates vars tidyselect expression (see tidyselect syntax) specifying columns use computation contrasts disjoint atomic vector size equal number columns x specifies groups predicates: elements disjoint vector equal, corresponding columns x present together single condition. x prepared partition(), using var_names() function x's column names convenient way create disjoint vector. excluded NULL list character vectors, character vector contains names columns must appear together single condition. min_length minimum size (minimum number predicates) condition generated (must greater equal 0). 0, empty condition generated first place. max_length maximum size (maximum number predicates) condition generated. equal Inf, maximum length conditions limited number available predicates. min_support minimum support condition trigger callback function . support condition relative frequency condition dataset x. logical data, equals relative frequency rows condition predicates TRUE . numerical (double) input, support computed mean (rows) multiplications predicate values. max_support maximum support condition trigger callback function . See argument min_support details support condition. method character string indicating contrast compute. One \"t\", parametric, \"wilcox\", non-parametric test equality position. alternative indicates alternative hypothesis must one \"two.sided\", \"greater\" \"less\". \"greater\" corresponds positive association, \"less\" negative association. h0 numeric value specifying null hypothesis test. \"t\" method, value mean. \"wilcox\" method, value median. default value 0. conf_level numeric value specifying level confidence interval. default value 0.95. max_p_value maximum p-value test pattern considered significant. p-value test greater max_p_value, pattern included result. wilcox_exact (used \"wilcox\" method ) logical value indicating whether exact p-value computed. NULL, exact p-value computed sample sizes less 50. See wilcox.test() exact argument information. Contrary behavior wilcox.test(), default value FALSE. wilcox_correct (used \"wilcox\" method ) logical value indicating whether continuity correction applied normal approximation p-value, wilcox_exact FALSE. See wilcox.test() correct argument information. wilcox_tol_root (used \"wilcox\" method ) numeric value specifying tolerance root-finding algorithm used compute exact p-value. See wilcox.test() tol.root argument information. wilcox_digits_rank (used \"wilcox\" method ) numeric value specifying number digits round ranks . See wilcox.test() digits.rank argument information. max_results maximum number generated conditions execute callback function . number found conditions exceeds max_results, function stops generating new conditions returns results. avoid long computations search, recommended set max_results reasonable positive value. Setting max_results Inf generate possible conditions. verbose logical scalar indicating whether print progress messages. threads number threads use parallel computation.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_baseline_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for conditions that yield in statistically significant one-sample test in selected variables. — dig_baseline_contrasts","text":"tibble found patterns rows. following columns always present: condition condition pattern character string form {p1 & p2 & ... & pn} p1, p2, ..., pn x's column names. support support condition, .e., relative frequency condition dataset x. var name contrast variable. estimate estimated mean median variable var. statistic statistic selected test. p_value p-value underlying test. n number rows sub-data corresponding condition. conf_int_lo lower bound confidence interval estimate. conf_int_hi upper bound confidence interval estimate. alternative character string indicating alternative hypothesis. value must one \"two.sided\", \"greater\", \"less\". method character string indicating method used test. comment character string additional information test (mainly error messages failure). \"t\" method, following additional columns also present (see also t.test()): df degrees freedom t test. stderr standard error mean.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig_baseline_contrasts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for conditions that yield in statistically significant one-sample test in selected variables. — dig_baseline_contrasts","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_complement_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for conditions that provide significant differences in selected variables to the rest of the data table — dig_complement_contrasts","title":"Search for conditions that provide significant differences in selected variables to the rest of the data table — dig_complement_contrasts","text":"Complement contrast patterns identify conditions significant difference numerical variable elements satisfy identified condition rest data table. Scheme: (var | C) != (var | C) statistically significant difference variable var group elements satisfy condition C group elements satisfy condition C. Example: (life_expectancy | smoker) < (life_expectancy | non-smoker) life expectancy people smoke cigarettes average significantly lower people smoke. complement contrast computed using two-sample statistical test, specified method argument. function computes complement contrast variables specified vars argument. Complement contrasts computed based sub-data corresponding conditions generated condition columns rest data table. Function #' dig_complement_contrasts() supports crisp conditions , .e., condition columns x must logical.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_complement_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for conditions that provide significant differences in selected variables to the rest of the data table — dig_complement_contrasts","text":"","code":"dig_complement_contrasts(   x,   condition = where(is.logical),   vars = where(is.numeric),   disjoint = var_names(colnames(x)),   excluded = NULL,   min_length = 0L,   max_length = Inf,   min_support = 0,   max_support = 1 - min_support,   method = \"t\",   alternative = \"two.sided\",   h0 = if (method == \"var\") 1 else 0,   conf_level = 0.95,   max_p_value = 0.05,   t_var_equal = FALSE,   wilcox_exact = FALSE,   wilcox_correct = TRUE,   wilcox_tol_root = 1e-04,   wilcox_digits_rank = Inf,   max_results = Inf,   verbose = FALSE,   threads = 1L )"},{"path":"https://beerda.github.io/nuggets/reference/dig_complement_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for conditions that provide significant differences in selected variables to the rest of the data table — dig_complement_contrasts","text":"x matrix data frame data search patterns . condition tidyselect expression (see tidyselect syntax) specifying columns use condition predicates vars tidyselect expression (see tidyselect syntax) specifying columns use computation contrasts disjoint atomic vector size equal number columns x specifies groups predicates: elements disjoint vector equal, corresponding columns x present together single condition. x prepared partition(), using var_names() function x's column names convenient way create disjoint vector. excluded NULL list character vectors, character vector contains names columns must appear together single condition. min_length minimum size (minimum number predicates) condition generated (must greater equal 0). 0, empty condition generated first place. max_length maximum size (maximum number predicates) condition generated. equal Inf, maximum length conditions limited number available predicates. min_support minimum support condition trigger callback function . support condition relative frequency condition dataset x. logical data, equals relative frequency rows condition predicates TRUE . numerical (double) input, support computed mean (rows) multiplications predicate values. max_support maximum support condition trigger callback function . See argument min_support details support condition. method character string indicating contrast compute. One \"t\", parametric, \"wilcox\", non-parametric test equality position, \"var\" F-test comparison variances two populations. alternative indicates alternative hypothesis must one \"two.sided\", \"greater\" \"less\". \"greater\" corresponds positive association, \"less\" negative association. h0 numeric value specifying null hypothesis test. \"t\" method, difference means. \"wilcox\" method, difference medians. \"var\" method, hypothesized ratio population variances. default value 1 \"var\" method, 0 otherwise. conf_level numeric value specifying level confidence interval. default value 0.95. max_p_value maximum p-value test pattern considered significant. p-value test greater max_p_value, pattern included result. t_var_equal (used \"t\" method ) logical value indicating whether variances two samples assumed equal. TRUE, pooled variance used estimate variance t-test. FALSE, Welch (Satterthwaite) approximation degrees freedom used. See t.test() var.equal argument information. wilcox_exact (used \"wilcox\" method ) logical value indicating whether exact p-value computed. NULL, exact p-value computed sample sizes less 50. See wilcox.test() exact argument information. Contrary behavior wilcox.test(), default value FALSE. wilcox_correct (used \"wilcox\" method ) logical value indicating whether continuity correction applied normal approximation p-value, wilcox_exact FALSE. See wilcox.test() correct argument information. wilcox_tol_root (used \"wilcox\" method ) numeric value specifying tolerance root-finding algorithm used compute exact p-value. See wilcox.test() tol.root argument information. wilcox_digits_rank (used \"wilcox\" method ) numeric value specifying number digits round ranks . See wilcox.test() digits.rank argument information. max_results maximum number generated conditions execute callback function . number found conditions exceeds max_results, function stops generating new conditions returns results. avoid long computations search, recommended set max_results reasonable positive value. Setting max_results Inf generate possible conditions. verbose logical scalar indicating whether print progress messages. threads number threads use parallel computation.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_complement_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for conditions that provide significant differences in selected variables to the rest of the data table — dig_complement_contrasts","text":"tibble found patterns rows. following columns always present: condition condition pattern character string form {p1 & p2 & ... & pn} p1, p2, ..., pn x's column names. support support condition, .e., relative frequency condition dataset x. var name contrast variable. estimate estimate value (see underlying test. statistic statistic selected test. p_value p-value underlying test. n_x number rows sub-data corresponding condition. n_y number rows sub-data corresponding negation condition. conf_int_lo lower bound confidence interval estimate. conf_int_hi upper bound confidence interval estimate. alternative character string indicating alternative hypothesis. value must one \"two.sided\", \"greater\", \"less\". method character string indicating method used test. comment character string additional information test (mainly error messages failure). \"t\" method, following additional columns also present (see also t.test()): df degrees freedom t test. stderr standard error mean difference.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig_complement_contrasts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for conditions that provide significant differences in selected variables to the rest of the data table — dig_complement_contrasts","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for paired contrast patterns — dig_contrasts","title":"Search for paired contrast patterns — dig_contrasts","text":"Contrast patterns generalization association rules allow specification condition significant difference statistical feature two numeric variables. Scheme: theta(xvar) >> theta(yvar) | C feature theta first variable xvar significantly higher feature theta second variable yvar condition C. Example: mean(daily_ice_cream_income) >> mean(daily_tea_income) | sunny mean daily ice-cream income significantly higher mean daily tea income condition sunny weather. contrast computed using statistical test, specified method argument. function computes contrast pairs variables, first variable specified xvars argument second variable specified yvars argument. contrast computed sub-data corresponding conditions generated condition columns. dig_contrasts() function supports crisp conditions , .e., condition columns must logical.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for paired contrast patterns — dig_contrasts","text":"","code":"dig_contrasts(   x,   condition = where(is.logical),   xvars = where(is.numeric),   yvars = where(is.numeric),   method = \"t\",   alternative = \"two.sided\",   min_length = 0L,   max_length = Inf,   min_support = 0,   max_p_value = 0.05,   threads = 1,   ... )"},{"path":"https://beerda.github.io/nuggets/reference/dig_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for paired contrast patterns — dig_contrasts","text":"x matrix data frame data search . condition tidyselect expression (see tidyselect syntax) specifying columns use condition predicates xvars tidyselect expression (see tidyselect syntax) specifying columns use computation contrasts yvars tidyselect expression (see tidyselect syntax) specifying columns use computation contrasts method character string indicating contrast compute. One \"t\", \"wilcox\", \"var\". \"t\" (resp. \"wilcos\") compute parametric (resp. non-parametric) test equality position, \"var\" performs F-test equality variance. alternative indicates alternative hypothesis must one \"two.sided\", \"greater\" \"less\". \"greater\" corresponds positive association, \"less\" negative association. min_length minimum size (minimum number predicates) condition generated (must greater equal 0). 0, empty condition generated first place. max_length maximum size (maximum number predicates) condition generated. equal Inf, maximum length conditions limited number available predicates. min_support minimum support condition trigger callback function . support condition relative frequency condition dataset x. logical data, equals relative frequency rows condition predicates TRUE . numerical (double) input, support computed mean (rows) multiplications predicate values. max_p_value maximum p-value test pattern considered significant. p-value test greater max_p_value, pattern included result. threads number threads use parallel computation. ... arguments passed underlying test function (t.test(), wilcox.test(), var.test() accordingly selected method).","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for paired contrast patterns — dig_contrasts","text":"tibble found patterns rows. following columns always present: condition condition pattern character string form {p1 & p2 & ... & pn} p1, p2, ..., pn x's column names. support support condition, .e., relative frequency condition dataset x. xvar name first variable contrast. yvar name second variable contrast. p_value p-value underlying test. rows number rows sub-data corresponding condition. alternative character string indicating alternative hypothesis. method character string indicating method used test. \"t\" method, following additional columns also present (see also t.test()): estimate_x estimated mean variable xvar. estimate_y estimated mean variable yvar. t_statistic t-statistic t test. df degrees freedom t test. conf_int_lo lower bound confidence interval. conf_int_hi upper bound confidence interval. stderr standard error mean difference. \"wilcox\" method, following additional columns also present (see also wilcox.test()): estimate estimate location parameter. W_statistic Wilcoxon rank sum statistic. conf_int_lo lower bound confidence interval. conf_int_hi upper bound confidence interval. \"var\" method, following additional columns also present (see also var.test()): estimate ratio sample variances variables xvar yvar. F_statistic value F test statistic. df1 numerator degrees freedom. df2 denominator degrees freedom. conf_int_lo lower bound confidence interval ratio population variances. conf_int_hi upper bound confidence interval ratio population variances.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig_contrasts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for paired contrast patterns — dig_contrasts","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for conditional correlations — dig_correlations","title":"Search for conditional correlations — dig_correlations","text":"Conditional correlations patterns identify strong relationships pairs numeric variables specific conditions. Scheme: xvar ~ yvar | Cxvar yvar highly correlates data satisfy condition C. Example: study_time ~ test_score | hard_exam hard exams, amount study time highly correlated obtained exam's test score. function computes correlations combinations xvars yvars columns x multiple sub-data corresponding conditions generated condition columns.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for conditional correlations — dig_correlations","text":"","code":"dig_correlations(   x,   condition = where(is.logical),   xvars = where(is.numeric),   yvars = where(is.numeric),   disjoint = var_names(colnames(x)),   excluded = NULL,   method = \"pearson\",   alternative = \"two.sided\",   exact = NULL,   min_length = 0L,   max_length = Inf,   min_support = 0,   max_support = 1,   max_results = Inf,   verbose = FALSE,   threads = 1 )"},{"path":"https://beerda.github.io/nuggets/reference/dig_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for conditional correlations — dig_correlations","text":"x matrix data frame data search . condition tidyselect expression (see tidyselect syntax) specifying columns use condition predicates xvars tidyselect expression (see tidyselect syntax) specifying columns use computation correlations yvars tidyselect expression (see tidyselect syntax) specifying columns use computation correlations disjoint atomic vector size equal number columns x specifies groups predicates: elements disjoint vector equal, corresponding columns x present together single condition. x prepared partition(), using var_names() function x's column names convenient way create disjoint vector. excluded NULL list character vectors, character vector contains names columns must appear together single condition. method character string indicating correlation coefficient used test. One \"pearson\", \"kendall\", \"spearman\" alternative indicates alternative hypothesis must one \"two.sided\", \"greater\" \"less\". \"greater\" corresponds positive association, \"less\" negative association. exact logical indicating whether exact p-value computed. Used Kendall's tau Spearman's rho. See stats::cor.test() information. min_length minimum size (minimum number predicates) condition generated (must greater equal 0). 0, empty condition generated first place. max_length maximum size (maximum number predicates) condition generated. equal Inf, maximum length conditions limited number available predicates. min_support minimum support condition trigger callback function . support condition relative frequency condition dataset x. logical data, equals relative frequency rows condition predicates TRUE . numerical (double) input, support computed mean (rows) multiplications predicate values. max_support maximum support condition trigger callback function . See argument min_support details support condition. max_results maximum number generated conditions execute callback function . number found conditions exceeds max_results, function stops generating new conditions returns results. avoid long computations search, recommended set max_results reasonable positive value. Setting max_results Inf generate possible conditions. verbose logical scalar indicating whether print progress messages. threads number threads use parallel computation.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for conditional correlations — dig_correlations","text":"tibble found patterns.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig_correlations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for conditional correlations — dig_correlations","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_correlations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for conditional correlations — dig_correlations","text":"","code":"# convert iris$Species into dummy logical variables d <- partition(iris, Species)  # find conditional correlations between all pairs of numeric variables dig_correlations(d,                  condition = where(is.logical),                  xvars = Sepal.Length:Petal.Width,                  yvars = Sepal.Length:Petal.Width) #> # A tibble: 24 × 10 #>    condition      support xvar  yvar  estimate  p_value method alternative  rows #>    <chr>            <dbl> <chr> <chr>    <dbl>    <dbl> <chr>  <chr>       <int> #>  1 {}               1     Sepa… Sepa…   -0.118 1.52e- 1 Pears… two.sided     150 #>  2 {}               1     Sepa… Peta…    0.872 1.04e-47 Pears… two.sided     150 #>  3 {}               1     Sepa… Peta…    0.818 2.33e-37 Pears… two.sided     150 #>  4 {}               1     Sepa… Peta…   -0.428 4.51e- 8 Pears… two.sided     150 #>  5 {}               1     Sepa… Peta…   -0.366 4.07e- 6 Pears… two.sided     150 #>  6 {}               1     Peta… Peta…    0.963 4.68e-86 Pears… two.sided     150 #>  7 {Species=seto…   0.333 Sepa… Sepa…    0.743 6.71e-10 Pears… two.sided      50 #>  8 {Species=seto…   0.333 Sepa… Peta…    0.267 6.07e- 2 Pears… two.sided      50 #>  9 {Species=seto…   0.333 Sepa… Peta…    0.278 5.05e- 2 Pears… two.sided      50 #> 10 {Species=seto…   0.333 Sepa… Peta…    0.178 2.17e- 1 Pears… two.sided      50 #> # ℹ 14 more rows #> # ℹ 1 more variable: condition_length <int>  # With `condition = NULL`, dig_correlations() computes correlations between # all pairs of numeric variables on the whole dataset only, which is an # alternative way of computing the correlation matrix dig_correlations(iris,                  condition = NULL,                  xvars = Sepal.Length:Petal.Width,                  yvars = Sepal.Length:Petal.Width) #> # A tibble: 6 × 10 #>   condition support xvar        yvar  estimate  p_value method alternative  rows #>   <chr>       <dbl> <chr>       <chr>    <dbl>    <dbl> <chr>  <chr>       <int> #> 1 {}              1 Sepal.Leng… Sepa…   -0.118 1.52e- 1 Pears… two.sided     150 #> 2 {}              1 Sepal.Leng… Peta…    0.872 1.04e-47 Pears… two.sided     150 #> 3 {}              1 Sepal.Leng… Peta…    0.818 2.33e-37 Pears… two.sided     150 #> 4 {}              1 Sepal.Width Peta…   -0.428 4.51e- 8 Pears… two.sided     150 #> 5 {}              1 Sepal.Width Peta…   -0.366 4.07e- 6 Pears… two.sided     150 #> 6 {}              1 Petal.Leng… Peta…    0.963 4.68e-86 Pears… two.sided     150 #> # ℹ 1 more variable: condition_length <int>"},{"path":"https://beerda.github.io/nuggets/reference/dig_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for grid-based rules — dig_grid","title":"Search for grid-based rules — dig_grid","text":"function creates grid column names specified xvars yvars (see var_grid()). , enumerates conditions created data x (calling dig()) condition row grid combinations, user-defined function f executed sub-data created x selecting rows x satisfy generated condition selecting columns grid's row. Function useful searching patterns based relationships pairs columns, dig_correlations().","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for grid-based rules — dig_grid","text":"","code":"dig_grid(   x,   f,   condition = where(is.logical),   xvars = where(is.numeric),   yvars = where(is.numeric),   disjoint = var_names(colnames(x)),   excluded = NULL,   allow = \"all\",   na_rm = FALSE,   type = \"crisp\",   min_length = 0L,   max_length = Inf,   min_support = 0,   max_support = 1,   max_results = Inf,   verbose = FALSE,   threads = 1L,   error_context = list(arg_x = \"x\", arg_f = \"f\", arg_condition = \"condition\", arg_xvars =     \"xvars\", arg_yvars = \"yvars\", arg_disjoint = \"disjoint\", arg_excluded = \"excluded\",     arg_allow = \"allow\", arg_na_rm = \"na_rm\", arg_type = \"type\", arg_min_length =     \"min_length\", arg_max_length = \"max_length\", arg_min_support = \"min_support\",     arg_max_support = \"max_support\", arg_max_results = \"max_results\", arg_verbose =     \"verbose\", arg_threads = \"threads\", call = current_env()) )"},{"path":"https://beerda.github.io/nuggets/reference/dig_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for grid-based rules — dig_grid","text":"x matrix data frame data search . f callback function executed generated condition. arguments callback function differ based value type argument (see ): type = \"crisp\" (, boolean), callback function f must accept single argument pd type data.frame single (yvars == NULL) two (yvars != NULL) columns, accessible pd[[1]] pd[[2]]. Data frame pd subset original data frame x rows satisfy generated condition. Optionally, callback function may accept argument nd subset original data frame x rows satisfy generated condition. type = \"fuzzy\", callback function f must accept argument d type data.frame single (yvars == NULL) two (yvars != NULL) columns, accessible d[[1]] d[[2]], numeric argument weights length number rows d. weights argument contains truth degree generated condition row d. truth degree number interval \\([0, 1]\\) represents degree satisfaction condition original data row. cases, function must return list scalar values, converted single row result final tibble. condition tidyselect expression (see tidyselect syntax) specifying columns use condition predicates. selected columns must logical numeric. numeric, fuzzy conditions considered. xvars tidyselect expression (see tidyselect syntax) specifying columns x, whose names used domain combinations use first place (xvar) yvars NULL tidyselect expression (see tidyselect syntax) specifying columns x, whose names used domain combinations use second place (yvar) disjoint atomic vector size equal number columns x specifies groups predicates: elements disjoint vector equal, corresponding columns x present together single condition. x prepared partition(), using var_names() function x's column names convenient way create disjoint vector. excluded NULL list character vectors, character vector contains names columns must appear together single condition. allow character string specifying columns allowed selected xvars yvars arguments. Possible values : \"\" - columns allowed selected \"numeric\" - numeric columns allowed selected na_rm logical value indicating whether remove rows missing values sub-data callback function f called type character string specifying type conditions processed. \"crisp\" type accepts logical columns condition predicates. \"fuzzy\" type accepts logical numeric columns condition predicates numeric data interval \\([0, 1]\\). callback function f differs based value type argument (see description f ). min_length minimum size (minimum number predicates) condition generated (must greater equal 0). 0, empty condition generated first place. max_length maximum size (maximum number predicates) condition generated. equal Inf, maximum length conditions limited number available predicates. min_support minimum support condition trigger callback function . support condition relative frequency condition dataset x. logical data, equals relative frequency rows condition predicates TRUE . numerical (double) input, support computed mean (rows) multiplications predicate values. max_support maximum support condition trigger callback function . See argument min_support details support condition. max_results maximum number generated conditions execute callback function . number found conditions exceeds max_results, function stops generating new conditions returns results. avoid long computations search, recommended set max_results reasonable positive value. Setting max_results Inf generate possible conditions. verbose logical scalar indicating whether print progress messages. threads number threads use parallel computation. error_context list details used error messages. argument useful dig_grid() called another function provide error messages, refer arguments calling function. list must contain following elements: arg_x - name argument x character string arg_condition - name argument condition character string arg_xvars - name argument xvars character string arg_yvars - name argument yvars character string call - environment evaluate error messages.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for grid-based rules — dig_grid","text":"tibble found patterns. row represents single call callback function f.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig_grid.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for grid-based rules — dig_grid","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_grid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for grid-based rules — dig_grid","text":"","code":"# *** Example of crisp (boolean) patterns: # dichotomize iris$Species crispIris <- partition(iris, Species)  # a simple callback function that computes mean difference of `xvar` and `yvar` f <- function(pd) {     list(m = mean(pd[[1]] - pd[[2]]),          n = nrow(pd))     }  # call f() for each condition created from column `Species` dig_grid(crispIris,          f,          condition = starts_with(\"Species\"),          xvars = starts_with(\"Sepal\"),          yvars = starts_with(\"Petal\"),          type = \"crisp\") #> # A tibble: 16 × 7 #>    condition            support xvar         yvar       m     n condition_length #>    <chr>                  <dbl> <chr>        <chr>  <dbl> <int>            <int> #>  1 {}                     1     Sepal.Length Peta…  2.09    150                0 #>  2 {}                     1     Sepal.Length Peta…  4.64    150                0 #>  3 {}                     1     Sepal.Width  Peta… -0.701   150                0 #>  4 {}                     1     Sepal.Width  Peta…  1.86    150                0 #>  5 {Species=setosa}       0.333 Sepal.Length Peta…  3.54     50                1 #>  6 {Species=setosa}       0.333 Sepal.Length Peta…  4.76     50                1 #>  7 {Species=setosa}       0.333 Sepal.Width  Peta…  1.97     50                1 #>  8 {Species=setosa}       0.333 Sepal.Width  Peta…  3.18     50                1 #>  9 {Species=versicolor}   0.333 Sepal.Length Peta…  1.68     50                1 #> 10 {Species=versicolor}   0.333 Sepal.Length Peta…  4.61     50                1 #> 11 {Species=versicolor}   0.333 Sepal.Width  Peta… -1.49     50                1 #> 12 {Species=versicolor}   0.333 Sepal.Width  Peta…  1.44     50                1 #> 13 {Species=virginica}    0.333 Sepal.Length Peta…  1.04     50                1 #> 14 {Species=virginica}    0.333 Sepal.Length Peta…  4.56     50                1 #> 15 {Species=virginica}    0.333 Sepal.Width  Peta… -2.58     50                1 #> 16 {Species=virginica}    0.333 Sepal.Width  Peta…  0.948    50                1  # *** Example of fuzzy patterns: # create fuzzy sets from Sepal columns fuzzyIris <- partition(iris,                        starts_with(\"Sepal\"),                        .method = \"triangle\",                        .breaks = 3)  # a simple callback function that computes a weighted mean of a difference of # `xvar` and `yvar` f <- function(d, weights) {     list(m = weighted.mean(d[[1]] - d[[2]], w = weights),          w = sum(weights)) }  # call f() for each fuzzy condition created from column fuzzy sets whose # names start with \"Sepal\" dig_grid(fuzzyIris,          f,          condition = starts_with(\"Sepal\"),          xvars = Petal.Length,          yvars = Petal.Width,          type = \"fuzzy\") #> # A tibble: 16 × 7 #>    condition                   support xvar  yvar      m      w condition_length #>    <chr>                         <dbl> <chr> <chr> <dbl>  <dbl>            <int> #>  1 {}                          1       Peta… Peta…  2.56 150                   0 #>  2 {Sepal.Width=(3.2;4.4;Inf)} 0.0933  Peta… Peta…  1.62  14.0                 1 #>  3 {Sepal.Length=(6.1;7.9;Inf… 0.129   Peta… Peta…  3.76  19.3                 1 #>  4 {Sepal.Width=(-Inf;2;3.2)}  0.212   Peta… Peta…  2.96  31.8                 1 #>  5 {Sepal.Length=(-Inf;4.3;6.… 0.271   Peta… Peta…  1.59  40.7                 1 #>  6 {Sepal.Length=(4.3;6.1;7.9… 0.600   Peta… Peta…  2.74  89.9                 1 #>  7 {Sepal.Width=(2;3.2;4.4)}   0.694   Peta… Peta…  2.56 104.                  1 #>  8 {Sepal.Length=(6.1;7.9;Inf… 0.00833 Peta… Peta…  4.22   1.25                2 #>  9 {Sepal.Length=(6.1;7.9;Inf… 0.0218  Peta… Peta…  3.87   3.26                2 #> 10 {Sepal.Length=(-Inf;4.3;6.… 0.0364  Peta… Peta…  1.22   5.45                2 #> 11 {Sepal.Length=(-Inf;4.3;6.… 0.0472  Peta… Peta…  2.23   7.08                2 #> 12 {Sepal.Length=(4.3;6.1;7.9… 0.0486  Peta… Peta…  1.47   7.30                2 #> 13 {Sepal.Length=(4.3;6.1;7.9… 0.143   Peta… Peta…  3.06  21.5                 2 #> 14 {Sepal.Length=(6.1;7.9;Inf… 0.0988  Peta… Peta…  3.70  14.8                 2 #> 15 {Sepal.Length=(-Inf;4.3;6.… 0.188   Peta… Peta…  1.50  28.2                 2 #> 16 {Sepal.Length=(4.3;6.1;7.9… 0.408   Peta… Peta…  2.78  61.2                 2"},{"path":"https://beerda.github.io/nuggets/reference/dig_implications.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for association rules — dig_implications","title":"Search for association rules — dig_implications","text":"Association rules identify conditions (antecedents) specific feature (consequent) present often. Scheme: => C condition satisfied, feature C present often. Example: university_edu & middle_age & IT_industry => high_income People middle age university education working industry likely high income. Antecedent usually set predicates, consequent C single predicate. following explanations need mathematical function \\(supp()\\), defined set \\(\\) predicates relative frequency rows satisfying predicates \\(\\). logical data, \\(supp()\\) equals relative frequency rows, predicates \\(i_1, i_2, \\ldots, i_n\\) \\(\\) TRUE. numerical (double) input, \\(supp()\\) computed mean (rows) truth degrees formula i_1 i_2 ... i_n, triangular norm selected t_norm argument. Association rules characterized following quality measures. Length rule number elements antecedent. Coverage rule equal \\(supp()\\). Consequent support rule equal \\(supp(\\{c\\})\\). Support rule equal \\(supp(\\cup \\{c\\})\\). Confidence rule fraction \\(supp() / supp(\\cup \\{c\\})\\).","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_implications.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for association rules — dig_implications","text":"","code":"dig_implications(   x,   antecedent = everything(),   consequent = everything(),   disjoint = var_names(colnames(x)),   min_length = 0L,   max_length = Inf,   min_coverage = 0,   min_support = 0,   min_confidence = 0,   contingency_table = FALSE,   measures = NULL,   t_norm = \"goguen\",   threads = 1,   ... )"},{"path":"https://beerda.github.io/nuggets/reference/dig_implications.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for association rules — dig_implications","text":"x matrix data frame data search . matrix must numeric (double) logical. x data frame column must either numeric (double) logical. antecedent tidyselect expression (see tidyselect syntax) specifying columns use antecedent (left) part rules consequent tidyselect expression (see tidyselect syntax) specifying columns use consequent (right) part rules disjoint atomic vector size equal number columns x specifies groups predicates: elements disjoint vector equal, corresponding columns x present together single condition. x prepared partition(), using var_names() function x's column names convenient way create disjoint vector. min_length minimum length, .e., minimum number predicates antecedent, rule generated. Value must greater equal 0. 0, rules empty antecedent generated first place. max_length maximum length, .e., maximum number predicates antecedent, rule generated. equal Inf, maximum length limited number available predicates. min_coverage minimum coverage rule dataset x. (See Description definition coverage.) min_support minimum support rule dataset x. (See Description definition support.) min_confidence minimum confidence rule dataset x. (See Description definition confidence.) contingency_table logical value indicating whether provide contingency table rule. TRUE, columns pp, pn, np, nn added output table. columns contain number rows satisfying antecedent consequent, antecedent consequent, consequent antecedent, neither antecedent consequent, respectively. measures character vector specifying additional quality measures compute. NULL, additional measures computed. Possible values \"lift\", \"conviction\", \"added_value\". See https://mhahsler.github.io/arules/docs/measures description measures. t_norm t-norm used compute conjunction weights. must one \"goedel\" (minimum t-norm), \"goguen\" (product t-norm), \"lukas\" (Lukasiewicz t-norm). threads number threads use parallel computation. ... arguments, currently unused.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_implications.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for association rules — dig_implications","text":"tibble found patterns computed quality measures.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig_implications.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for association rules — dig_implications","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_implications.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for association rules — dig_implications","text":"","code":"d <- partition(mtcars, .breaks = 2) dig_associations(d,                  antecedent = !starts_with(\"mpg\"),                  consequent = starts_with(\"mpg\"),                  min_support = 0.3,                  min_confidence = 0.8,                  measures = c(\"lift\", \"conviction\")) #> # A tibble: 524 × 10 #>    antecedent        consequent support confidence coverage conseq_support count #>    <chr>             <chr>        <dbl>      <dbl>    <dbl>          <dbl> <dbl> #>  1 {wt=(3.47;Inf]}   {mpg=(-In…   0.344      1        0.344          0.719    11 #>  2 {cyl=(6;Inf]}     {mpg=(-In…   0.438      1        0.438          0.719    14 #>  3 {disp=(272;Inf]}  {mpg=(-In…   0.438      1        0.438          0.719    14 #>  4 {vs=(-Inf;0.5]}   {mpg=(-In…   0.531      0.944    0.562          0.719    17 #>  5 {drat=(-Inf;3.84… {mpg=(-In…   0.531      0.895    0.594          0.719    17 #>  6 {am=(-Inf;0.5]}   {mpg=(-In…   0.531      0.895    0.594          0.719    17 #>  7 {qsec=(-Inf;18.7… {mpg=(-In…   0.594      0.826    0.719          0.719    19 #>  8 {cyl=(6;Inf],wt=… {mpg=(-In…   0.344      1        0.344          0.719    11 #>  9 {disp=(272;Inf],… {mpg=(-In…   0.344      1        0.344          0.719    11 #> 10 {cyl=(6;Inf],dis… {mpg=(-In…   0.438      1        0.438          0.719    14 #> # ℹ 514 more rows #> # ℹ 3 more variables: antecedent_length <int>, lift <dbl>, conviction <dbl>"},{"path":"https://beerda.github.io/nuggets/reference/dig_paired_baseline_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for conditions that provide significant differences between paired variables — dig_paired_baseline_contrasts","title":"Search for conditions that provide significant differences between paired variables — dig_paired_baseline_contrasts","text":"Paired baseline contrast patterns identify conditions significant difference statistical feature two paired numeric variables. Scheme: (xvar - yvar) != 0 | C statistically significant difference paired variables xvar yvar condition C. Example: (daily_ice_cream_income - daily_tea_income) > 0 | sunny condition sunny weather, paired test shows daily ice-cream income significantly higher daily tea income. paired baseline contrast  computed using paired version statistical test, specified method argument. function computes paired contrast pairs variables, first variable specified xvars argument second variable specified yvars argument. Paired baseline contrasts computed sub-data corresponding conditions generated condition columns. Function dig_paired_baseline_contrasts() supports crisp conditions , .e., condition columns x must logical.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_paired_baseline_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for conditions that provide significant differences between paired variables — dig_paired_baseline_contrasts","text":"","code":"dig_paired_baseline_contrasts(   x,   condition = where(is.logical),   xvars = where(is.numeric),   yvars = where(is.numeric),   disjoint = var_names(colnames(x)),   excluded = NULL,   min_length = 0L,   max_length = Inf,   min_support = 0,   max_support = 1,   method = \"t\",   alternative = \"two.sided\",   h0 = 0,   conf_level = 0.95,   max_p_value = 1,   t_var_equal = FALSE,   wilcox_exact = FALSE,   wilcox_correct = TRUE,   wilcox_tol_root = 1e-04,   wilcox_digits_rank = Inf,   max_results = Inf,   verbose = FALSE,   threads = 1 )"},{"path":"https://beerda.github.io/nuggets/reference/dig_paired_baseline_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for conditions that provide significant differences between paired variables — dig_paired_baseline_contrasts","text":"x matrix data frame data search patterns . condition tidyselect expression (see tidyselect syntax) specifying columns use condition predicates xvars tidyselect expression (see tidyselect syntax) specifying columns use computation contrasts yvars tidyselect expression (see tidyselect syntax) specifying columns use computation contrasts disjoint atomic vector size equal number columns x specifies groups predicates: elements disjoint vector equal, corresponding columns x present together single condition. x prepared partition(), using var_names() function x's column names convenient way create disjoint vector. excluded NULL list character vectors, character vector contains names columns must appear together single condition. min_length minimum size (minimum number predicates) condition generated (must greater equal 0). 0, empty condition generated first place. max_length maximum size (maximum number predicates) condition generated. equal Inf, maximum length conditions limited number available predicates. min_support minimum support condition trigger callback function . support condition relative frequency condition dataset x. logical data, equals relative frequency rows condition predicates TRUE . numerical (double) input, support computed mean (rows) multiplications predicate values. max_support maximum support condition trigger callback function . See argument min_support details support condition. method character string indicating contrast compute. One \"t\", parametric, \"wilcox\", non-parametric test equality position. alternative indicates alternative hypothesis must one \"two.sided\", \"greater\" \"less\". \"greater\" corresponds positive association, \"less\" negative association. h0 numeric value specifying null hypothesis test. \"t\" method, difference means. \"wilcox\" method, difference medians. default value 0. conf_level numeric value specifying level confidence interval. default value 0.95. max_p_value maximum p-value test pattern considered significant. p-value test greater max_p_value, pattern included result. t_var_equal (used \"t\" method ) logical value indicating whether variances two samples assumed equal. TRUE, pooled variance used estimate variance t-test. FALSE, Welch (Satterthwaite) approximation degrees freedom used. See t.test() var.equal argument information. wilcox_exact (used \"wilcox\" method ) logical value indicating whether exact p-value computed. NULL, exact p-value computed sample sizes less 50. See wilcox.test() exact argument information. Contrary behavior wilcox.test(), default value FALSE. wilcox_correct (used \"wilcox\" method ) logical value indicating whether continuity correction applied normal approximation p-value, wilcox_exact FALSE. See wilcox.test() correct argument information. wilcox_tol_root (used \"wilcox\" method ) numeric value specifying tolerance root-finding algorithm used compute exact p-value. See wilcox.test() tol.root argument information. wilcox_digits_rank (used \"wilcox\" method ) numeric value specifying number digits round ranks . See wilcox.test() digits.rank argument information. max_results maximum number generated conditions execute callback function . number found conditions exceeds max_results, function stops generating new conditions returns results. avoid long computations search, recommended set max_results reasonable positive value. Setting max_results Inf generate possible conditions. verbose logical scalar indicating whether print progress messages. threads number threads use parallel computation.","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_paired_baseline_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for conditions that provide significant differences between paired variables — dig_paired_baseline_contrasts","text":"tibble found patterns rows. following columns always present: condition condition pattern character string form {p1 & p2 & ... & pn} p1, p2, ..., pn x's column names. support support condition, .e., relative frequency condition dataset x. xvar name first variable contrast. yvar name second variable contrast. estimate estimated difference variable var. statistic statistic selected test. p_value p-value underlying test. n number rows sub-data corresponding condition. conf_int_lo lower bound confidence interval estimate. conf_int_hi upper bound confidence interval estimate. alternative character string indicating alternative hypothesis. value must one \"two.sided\", \"greater\", \"less\". method character string indicating method used test. comment character string additional information test (mainly error messages failure). \"t\" method, following additional columns also present (see also t.test()): df degrees freedom t test. stderr standard error mean difference.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/dig_paired_baseline_contrasts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Search for conditions that provide significant differences between paired variables — dig_paired_baseline_contrasts","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/dig_paired_baseline_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for conditions that provide significant differences between paired variables — dig_paired_baseline_contrasts","text":"","code":"# Compute ratio of sepal and petal length and width for iris dataset crispIris <- iris crispIris$Sepal.Ratio <- iris$Sepal.Length / iris$Sepal.Width crispIris$Petal.Ratio <- iris$Petal.Length / iris$Petal.Width  # Create predicates from the Species column crispIris <- partition(crispIris, Species)  # Compute paired contrasts for ratios of sepal and petal length and width dig_paired_baseline_contrasts(crispIris,                               condition = where(is.logical),                               xvars = Sepal.Ratio,                               yvars = Petal.Ratio,                               method = \"t\",                               min_support = 0.1) #> # A tibble: 4 × 16 #>   condition  support xvar  yvar  estimate statistic    df  p_value     n conf_lo #>   <chr>        <dbl> <chr> <chr>    <dbl>     <dbl> <dbl>    <dbl> <int>   <dbl> #> 1 {}           1     Sepa… Peta…   -2.36      -10.5   149 1.31e-19   150  -2.80  #> 2 {Species=…   0.333 Sepa… Peta…   -5.44      -13.5    49 4.41e-18    50  -6.25  #> 3 {Species=…   0.333 Sepa… Peta…   -1.08      -25.6    49 5.13e-30    50  -1.17  #> 4 {Species=…   0.333 Sepa… Peta…   -0.550     -11.1    49 4.85e-15    50  -0.649 #> # ℹ 6 more variables: conf_hi <dbl>, stderr <dbl>, alternative <chr>, #> #   method <chr>, comment <chr>, condition_length <int>"},{"path":"https://beerda.github.io/nuggets/reference/fire.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain truth-degrees of conditions — fire","title":"Obtain truth-degrees of conditions — fire","text":"Given data frame matrix truth values predicates, compute truth values given vector conditions.","code":""},{"path":"https://beerda.github.io/nuggets/reference/fire.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain truth-degrees of conditions — fire","text":"","code":"fire(x, condition, t_norm = \"goguen\")"},{"path":"https://beerda.github.io/nuggets/reference/fire.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain truth-degrees of conditions — fire","text":"x matrix data frame. matrix must numeric (double) logical. x data frame column must either numeric (double) logical. condition character vector conditions, element formatted format_condition(). E.g., \"{p1,p2,p3}\" condition three predicates \"p1\", \"p2\", \"p3\". predicates present condition must exist column names x. t_norm t-norm used compute conjunction weights. must one \"goedel\" (minimum t-norm), \"goguen\" (product t-norm), \"lukas\" (Lukasiewicz t-norm).","code":""},{"path":"https://beerda.github.io/nuggets/reference/fire.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain truth-degrees of conditions — fire","text":"numeric matrix values interval \\([0,1]\\) indicating truth values. resulting matrix nrow(x) rows length(condition) columns. , value -th row j-th column corresponds truth value j-th condition evaluated -th data row.","code":""},{"path":"https://beerda.github.io/nuggets/reference/fire.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Obtain truth-degrees of conditions — fire","text":"element condition character string format \"{p1,p2,p3}\", \"p1\", \"p2\", \"p3\" predicates. Data x must contain columns whose names correspond predicates used conditions. condition evaluated data rows elementary conjunction, conjunction operation specified t_norm argument. empty condition, {}, always evaluated 1.","code":""},{"path":"https://beerda.github.io/nuggets/reference/fire.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Obtain truth-degrees of conditions — fire","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/fire.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain truth-degrees of conditions — fire","text":"","code":"d <- data.frame(a = c(  1, 0.8, 0.5, 0.2,   0),                 b = c(0.5,   1, 0.5,   0,   1),                 c = c(0.9, 0.9, 0.1, 0.8, 0.7)) fire(d, c(\"{a,c}\", \"{}\", \"{a,b,c}\")) #>      [,1] [,2]  [,3] #> [1,] 0.90    1 0.450 #> [2,] 0.72    1 0.720 #> [3,] 0.05    1 0.025 #> [4,] 0.16    1 0.000 #> [5,] 0.00    1 0.000"},{"path":"https://beerda.github.io/nuggets/reference/format_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a vector of predicates into a string with a condition — format_condition","title":"Format a vector of predicates into a string with a condition — format_condition","text":"Function takes character vector predicates returns formatted condition. format condition string predicates separated commas enclosed curly braces.","code":""},{"path":"https://beerda.github.io/nuggets/reference/format_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a vector of predicates into a string with a condition — format_condition","text":"","code":"format_condition(condition)"},{"path":"https://beerda.github.io/nuggets/reference/format_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a vector of predicates into a string with a condition — format_condition","text":"condition character vector predicates formatted","code":""},{"path":"https://beerda.github.io/nuggets/reference/format_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format a vector of predicates into a string with a condition — format_condition","text":"character scalar formatted condition","code":""},{"path":"https://beerda.github.io/nuggets/reference/format_condition.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Format a vector of predicates into a string with a condition — format_condition","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/format_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format a vector of predicates into a string with a condition — format_condition","text":"","code":"format_condition(NULL)              # returns {} #> [1] \"{}\" format_condition(c(\"a\", \"b\", \"c\"))  # returns {a,b,c} #> [1] \"{a,b,c}\""},{"path":"https://beerda.github.io/nuggets/reference/is_almost_constant.html","id":null,"dir":"Reference","previous_headings":"","what":"Tests if almost all values in a vector are the same. — is_almost_constant","title":"Tests if almost all values in a vector are the same. — is_almost_constant","text":"Function tests almost values vector . function returns TRUE proportion frequent value greater equal threshold argument.","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_almost_constant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tests if almost all values in a vector are the same. — is_almost_constant","text":"","code":"is_almost_constant(x, threshold = 1, na_rm = FALSE)"},{"path":"https://beerda.github.io/nuggets/reference/is_almost_constant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tests if almost all values in a vector are the same. — is_almost_constant","text":"x vector tested threshold double scalar interval \\([0,1]\\) specifies threshold proportion frequent value na_rm flag indicating whether remove NA values testing proportion frequent value. , na_rm TRUE, proportion calculated non-NA values . na_rm FALSE, proportion calculated values value NA considered normal value (.e., much NAs can make vector almost constant ).","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_almost_constant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tests if almost all values in a vector are the same. — is_almost_constant","text":"x empty one value, function returns TRUE. x contains NA values, function returns TRUE. proportion frequent value greater equal threshold argument, function returns TRUE. Otherwise, function returns FALSE.","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_almost_constant.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Tests if almost all values in a vector are the same. — is_almost_constant","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_almost_constant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tests if almost all values in a vector are the same. — is_almost_constant","text":"","code":"is_almost_constant(1) #> [1] TRUE is_almost_constant(1:10) #> [1] FALSE is_almost_constant(c(NA, NA, NA), na_rm = TRUE) #> [1] TRUE is_almost_constant(c(NA, NA, NA), na_rm = FALSE) #> [1] TRUE is_almost_constant(c(NA, NA, NA, 1, 2), threshold = 0.5, na_rm = FALSE) #> [1] TRUE is_almost_constant(c(NA, NA, NA, 1, 2), threshold = 0.5, na_rm = TRUE) #> [1] TRUE"},{"path":"https://beerda.github.io/nuggets/reference/is_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether the given list of character vectors contains a list of valid conditions. — is_condition","title":"Check whether the given list of character vectors contains a list of valid conditions. — is_condition","text":"valid condition character vector predicates, predicate corresponds column name related data frame. function checks whether given list character vectors x contains predicates can found column names given data frame data.","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether the given list of character vectors contains a list of valid conditions. — is_condition","text":"","code":"is_condition(x, data)"},{"path":"https://beerda.github.io/nuggets/reference/is_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether the given list of character vectors contains a list of valid conditions. — is_condition","text":"x list character vector data matrix data frame","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether the given list of character vectors contains a list of valid conditions. — is_condition","text":"logical vector indicating whether element list x contains character vector elements vector column names data","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_condition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check whether the given list of character vectors contains a list of valid conditions. — is_condition","text":"Note empty character vector considered valid condition .","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/is_condition.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check whether the given list of character vectors contains a list of valid conditions. — is_condition","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether the given list of character vectors contains a list of valid conditions. — is_condition","text":"","code":"d <- data.frame(foo = 1:5, bar = 1:5, blah = 1:5) is_condition(list(\"foo\"), d) #> [1] TRUE is_condition(list(c(\"bar\", \"blah\"), NULL, c(\"foo\", \"bzz\")), d) #> [1]  TRUE  TRUE FALSE"},{"path":"https://beerda.github.io/nuggets/reference/is_degree.html","id":null,"dir":"Reference","previous_headings":"","what":"Tests whether the given argument is a numeric value from the interval \\([0,1]\\) — is_degree","title":"Tests whether the given argument is a numeric value from the interval \\([0,1]\\) — is_degree","text":"Tests whether given argument numeric value interval \\([0,1]\\)","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_degree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tests whether the given argument is a numeric value from the interval \\([0,1]\\) — is_degree","text":"","code":"is_degree(x, na_rm = FALSE)"},{"path":"https://beerda.github.io/nuggets/reference/is_degree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tests whether the given argument is a numeric value from the interval \\([0,1]\\) — is_degree","text":"x value tested na_rm whether ignore NA values","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_degree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tests whether the given argument is a numeric value from the interval \\([0,1]\\) — is_degree","text":"TRUE x numeric vector, matrix array values 0 1, otherwise, FALSE returned. na_rm TRUE, NA values treated valid values. na_rm FALSE x contains NA values, FALSE returned.","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_degree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Tests whether the given argument is a numeric value from the interval \\([0,1]\\) — is_degree","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine whether the first vector is a subset of the second vector — is_subset","title":"Determine whether the first vector is a subset of the second vector — is_subset","text":"Determine whether first vector subset second vector","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine whether the first vector is a subset of the second vector — is_subset","text":"","code":"is_subset(x, y)"},{"path":"https://beerda.github.io/nuggets/reference/is_subset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine whether the first vector is a subset of the second vector — is_subset","text":"x first vector y second vector","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_subset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine whether the first vector is a subset of the second vector — is_subset","text":"TRUE x subset y, FALSE otherwise. x considered subset y elements x also y, .e., setdiff(x, y) vector length 0.","code":""},{"path":"https://beerda.github.io/nuggets/reference/is_subset.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Determine whether the first vector is a subset of the second vector — is_subset","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/nuggets-package.html","id":null,"dir":"Reference","previous_headings":"","what":"nuggets: Extensible Data Pattern Searching Framework — nuggets-package","title":"nuggets: Extensible Data Pattern Searching Framework — nuggets-package","text":"Extensible framework subgroup discovery (Atzmueller (2015) doi:10.1002/widm.1144 ), contrast patterns (Chen (2022) doi:10.48550/arXiv.2209.13556 ), emerging patterns (Dong (1999) doi:10.1145/312129.312191 ), association rules (Agrawal (1994) https://www.vldb.org/conf/1994/P487.PDF) conditional correlations (Hájek (1978) doi:10.1007/978-3-642-66943-9 ). crisp (Boolean, binary) fuzzy data supported. generates conditions form elementary conjunctions, evaluates dataset checks induced sub-data interesting statistical properties. user-defined function may defined evaluate generated condition search custom patterns.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/nuggets-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nuggets: Extensible Data Pattern Searching Framework — nuggets-package","text":"Maintainer: Michal Burda michal.burda@osu.cz (ORCID)","code":""},{"path":"https://beerda.github.io/nuggets/reference/parse_condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert character vector of conditions into a list of vectors of predicates — parse_condition","title":"Convert character vector of conditions into a list of vectors of predicates — parse_condition","text":"Function takes character vector conditions returns list vectors predicates. element list corresponds one condition. condition string predicates separated commas enclosed curly braces, returned format_condition(). function splits condition string vector predicates.","code":""},{"path":"https://beerda.github.io/nuggets/reference/parse_condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert character vector of conditions into a list of vectors of predicates — parse_condition","text":"","code":"parse_condition(..., .sort = FALSE)"},{"path":"https://beerda.github.io/nuggets/reference/parse_condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert character vector of conditions into a list of vectors of predicates — parse_condition","text":"... character vectors conditions parsed. .sort flag indicating whether sort predicates result.","code":""},{"path":"https://beerda.github.io/nuggets/reference/parse_condition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert character vector of conditions into a list of vectors of predicates — parse_condition","text":"list vectors predicates element corresponding one condition.","code":""},{"path":"https://beerda.github.io/nuggets/reference/parse_condition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert character vector of conditions into a list of vectors of predicates — parse_condition","text":"multiple vectors conditions passed, processed separately result merged single list element-wisely. lengths vectors different, shorter vectors recycled.","code":""},{"path":"https://beerda.github.io/nuggets/reference/parse_condition.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert character vector of conditions into a list of vectors of predicates — parse_condition","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/parse_condition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert character vector of conditions into a list of vectors of predicates — parse_condition","text":"","code":"parse_condition(c(\"{a}\", \"{x=1, z=2, y=3}\", \"{}\")) #> [[1]] #> [1] \"a\" #>  #> [[2]] #> [1] \"x=1\" \"z=2\" \"y=3\" #>  #> [[3]] #> character(0) #>  parse_condition(c(\"{b}\", \"{x=1, z=2, y=3}\", \"{q}\", \"{}\"),                 c(\"{a}\", \"{v=10, w=11}\",    \"{}\",  \"{r,s,t}\")) #> [[1]] #> [1] \"b\" \"a\" #>  #> [[2]] #> [1] \"x=1\"  \"z=2\"  \"y=3\"  \"v=10\" \"w=11\" #>  #> [[3]] #> [1] \"q\" #>  #> [[4]] #> [1] \"r\" \"s\" \"t\" #>"},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":"Convert selected columns data frame either dummy logical columns, membership degrees fuzzy sets, leaving remaining columns untouched. column selected transformation typically results multiple columns output.","code":""},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":"","code":"partition(   .data,   .what = everything(),   ...,   .breaks = NULL,   .labels = NULL,   .na = TRUE,   .keep = FALSE,   .method = \"crisp\",   .right = TRUE,   .span = 1,   .inc = 1 )"},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":".data data frame processed .tidyselect expression (see tidyselect syntax) specifying columns transformed ... optional tidyselect expressions selecting additional columns processed .breaks numeric columns, either integer scalar numeric vector. .breaks integer scalar, specifies number resulting intervals break numeric column (.method=\"crisp\") number target fuzzy sets (.method=\"triangle\" .method=\"raisedcos). .breaks vector, values specify borders intervals (.method=\"crisp\") breaking points fuzzy sets. .labels character vector specifying names used construct newly created column names. NULL, labels generated automatically. .na TRUE, additional logical column created source column contains NA values. column named x, newly created column's name x=NA. .keep TRUE, original columns transformed remain present resulting data frame. .method method transformation numeric columns. Either \"crisp\", \"triangle\", \"raisedcos\" required. .right .method=\"crisp\", argument specifies intervals closed right (open left) vice versa. .span span intervals numeric columns. .method=\"crisp\", argument specifies number consecutive breaks single resulting interval. .method=\"triangle\" .method=\"raisedcos\", argument specifies number breaks form core fuzzy set, (.e. membership degrees 1). .span = 1, fuzzy set triangular shape single value membership equal 1, .span = 2, fuzzy set trapezoidal shape. .inc many breaks move right creating next column numeric column x. words, .inc = 1, resulting columns created (shifting breaks 1), .inc = 2, first, third, fifth, etc. columns created, .e., every second resulting column skipped.","code":""},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":"tibble created transforming .data.","code":""},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":"Transformations performed function typically useful preprocessing step using dig() function derivatives (dig_correlations(), dig_paired_baseline_contrasts(), dig_associations()). transformation selected columns differ based type. Concretely: logical column x transformed pair logical columns, x=TRUE andx=FALSE; factor column x, levels l1, l2, l3, transformed three logical columns named x=l1, x=l2, x=l3; numeric columnx transformed accordingly .method argument: .method=\"crisp\", column first transformed factor intervals factor levels processed factor (see ); .method (triangle raisedcos), several new columns created, column numeric values interval \\([0,1]\\) represents certain fuzzy set (either triangular raised-cosinal). Details transformation numeric columns can specified additional arguments (.breaks, .labels, .right). processing source numeric columns quite complex depends following arguments: .method, .breaks, .right, .span, .inc.","code":""},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":"crisp-transformation-of-numeric-data","dir":"Reference","previous_headings":"","what":"Crisp transformation of numeric data","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":".method = \"crisp\", numeric column transformed set logical columns column represents certain interval values. intervals determined .breaks argument. .breaks integer scalar, specifies number resulting intervals break numeric column . intervals obtained automatically source column splitting range source values .breaks intervals equal length. first last interval defined minimum infinity first break last break maximum infinity, respectively. .breaks vector, values specify manual borders intervals. (Infinite values allowed.) .span = 1 .inc = 1, intervals consecutive non-overlapping. .breaks = c(1, 3, 5, 7, 9, 11) .right = TRUE, example, following intervals considered: \\((1;3]\\), \\((3;5]\\), \\((5;7]\\), \\((7;9]\\), \\((9;11]\\). (.right = FALSE, intervals : \\([1;3)\\), \\([3;5)\\), \\([5;7)\\), \\([7;9)\\), \\([9;11)\\).) .span > 1, intervals overlap .span breaks. .span = 2, .inc = 1, .right = TRUE, intervals : \\((1;5]\\), \\((3;7]\\), \\((5;9]\\), \\((7;11]\\). can seen, far next interval created shifting 1 position .breaks. .inc argument modifies shift. .inc = 2 .span = 1, intervals : \\((1;3]\\), \\((5;7]\\), \\((9;11]\\). .span = 2 .inc = 3, intervals : \\((1;5]\\), \\((9;11]\\).","code":""},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":"fuzzy-transformation-of-numeric-data","dir":"Reference","previous_headings":"","what":"Fuzzy transformation of numeric data","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":".method = \"triangle\" .method = \"raisedcos\", numeric column transformed set columns column represents membership degrees certain fuzzy set. shape underlying fuzzy sets determined .breaks argument. .breaks integer scalar, specifies number target fuzzy sets. breaks determined automatically source data column similarly crisp transformation described . .breaks vector, values specify breaking points fuzzy sets. Infinite values breaks produce fuzzy sets open borders. .span = 1, underlying fuzzy set determined three consecutive breaks. Outside breaks, membership degree 0. interval first two breaks, membership degree increasing interval last two breaks, membership degree decreasing. Hence membership degree 1 obtained values equal middle break. practically forms fuzzy sets triangular raised-cosinal shape. .span > 1, fuzzy set determined four breaks. Outside breaks, membership degree 0. interval first second break, membership degree increasing, interval third fourth break, membership degree decreasing, interval second third break, membership degree 1. practically forms fuzzy sets trapezoidal shape. Similar crisp transformation, .inc argument determines shift breaks creating next underlying fuzzy set. Let .breaks = c(1, 3, 5, 7, 9, 11). .span = 1 .inc = 1, fuzzy sets determined following triplets effectively triangular raised-cosinal shape: \\((1;3;5)\\), \\((3;5;7)\\), \\((5;7;9)\\), \\((7;9;11)\\). .span = 2 .inc = 1, fuzzy sets determined following quadruplets: \\((1;3;5;7)\\), \\((3;5;7;9)\\), \\((5;7;9;11)\\). fuzzy sets trapezoidal shape linear (.method = \"triangle\") cosine (.method = \"raisedcos\") increasing decreasing border-parts. .span = 1 .inc = 3, fuzzy sets determined following triplets: \\((1;3;5)\\), \\((7;9;11)\\) skipping 2nd 3rd fuzzy sets. See examples details.","code":""},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/partition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert columns of data frame to Boolean or fuzzy sets (of triangular, trapezoidal, or raised-cosinal shape) — partition","text":"","code":"# transform logical columns and factors d <- data.frame(a = c(TRUE, TRUE, FALSE),                 b = factor(c(\"A\", \"B\", \"A\")),                 c = c(1, 2, 3)) partition(d, a, b) #> # A tibble: 3 × 5 #>       c `a=T` `a=F` `b=A` `b=B` #>   <dbl> <lgl> <lgl> <lgl> <lgl> #> 1     1 TRUE  FALSE TRUE  FALSE #> 2     2 TRUE  FALSE FALSE TRUE  #> 3     3 FALSE TRUE  TRUE  FALSE  # transform numeric columns to logical columns (crisp transformation) partition(CO2, conc:uptake, .method = \"crisp\", .breaks = 3) #> # A tibble: 84 × 9 #>    Plant Type   Treatment  `conc=(-Inf;397]` `conc=(397;698]` `conc=(698;Inf]` #>    <ord> <fct>  <fct>      <lgl>             <lgl>            <lgl>            #>  1 Qn1   Quebec nonchilled TRUE              FALSE            FALSE            #>  2 Qn1   Quebec nonchilled TRUE              FALSE            FALSE            #>  3 Qn1   Quebec nonchilled TRUE              FALSE            FALSE            #>  4 Qn1   Quebec nonchilled TRUE              FALSE            FALSE            #>  5 Qn1   Quebec nonchilled FALSE             TRUE             FALSE            #>  6 Qn1   Quebec nonchilled FALSE             TRUE             FALSE            #>  7 Qn1   Quebec nonchilled FALSE             FALSE            TRUE             #>  8 Qn2   Quebec nonchilled TRUE              FALSE            FALSE            #>  9 Qn2   Quebec nonchilled TRUE              FALSE            FALSE            #> 10 Qn2   Quebec nonchilled TRUE              FALSE            FALSE            #> # ℹ 74 more rows #> # ℹ 3 more variables: `uptake=(-Inf;20.3]` <lgl>, `uptake=(20.3;32.9]` <lgl>, #> #   `uptake=(32.9;Inf]` <lgl>  # transform numeric columns to triangular fuzzy sets: partition(CO2, conc:uptake, .method = \"triangle\", .breaks = 3) #> # A tibble: 84 × 9 #>    Plant Type   Treatment  `conc=(-Inf;95;548)` `conc=(95;548;1000)` #>    <ord> <fct>  <fct>                     <dbl>                <dbl> #>  1 Qn1   Quebec nonchilled                1                    0     #>  2 Qn1   Quebec nonchilled                0.823                0.177 #>  3 Qn1   Quebec nonchilled                0.658                0.342 #>  4 Qn1   Quebec nonchilled                0.437                0.563 #>  5 Qn1   Quebec nonchilled                0.106                0.894 #>  6 Qn1   Quebec nonchilled                0                    0.719 #>  7 Qn1   Quebec nonchilled                0                    0     #>  8 Qn2   Quebec nonchilled                1                    0     #>  9 Qn2   Quebec nonchilled                0.823                0.177 #> 10 Qn2   Quebec nonchilled                0.658                0.342 #> # ℹ 74 more rows #> # ℹ 4 more variables: `conc=(548;1000;Inf)` <dbl>, #> #   `uptake=(-Inf;7.7;26.6)` <dbl>, `uptake=(7.7;26.6;45.5)` <dbl>, #> #   `uptake=(26.6;45.5;Inf)` <dbl>  # transform numeric columns to raised-cosinal fuzzy sets partition(CO2, conc:uptake, .method = \"raisedcos\", .breaks = 3) #> # A tibble: 84 × 9 #>    Plant Type   Treatment  `conc=(-Inf;95;548)` `conc=(95;548;1000)` #>    <ord> <fct>  <fct>                     <dbl>                <dbl> #>  1 Qn1   Quebec nonchilled               1                    0      #>  2 Qn1   Quebec nonchilled               0.925                0.0750 #>  3 Qn1   Quebec nonchilled               0.738                0.262  #>  4 Qn1   Quebec nonchilled               0.402                0.598  #>  5 Qn1   Quebec nonchilled               0.0274               0.973  #>  6 Qn1   Quebec nonchilled               0                    0.818  #>  7 Qn1   Quebec nonchilled               0                    0      #>  8 Qn2   Quebec nonchilled               1                    0      #>  9 Qn2   Quebec nonchilled               0.925                0.0750 #> 10 Qn2   Quebec nonchilled               0.738                0.262  #> # ℹ 74 more rows #> # ℹ 4 more variables: `conc=(548;1000;Inf)` <dbl>, #> #   `uptake=(-Inf;7.7;26.6)` <dbl>, `uptake=(7.7;26.6;45.5)` <dbl>, #> #   `uptake=(26.6;45.5;Inf)` <dbl>  # transform numeric columns to trapezoidal fuzzy sets overlapping in non-core # regions so that the membership degrees sum to 1 along the consecutive fuzzy sets # (i.e., the so-called Ruspini condition is met) partition(CO2, conc:uptake, .method = \"triangle\", .breaks = 3, .span = 2, .inc = 2) #> # A tibble: 84 × 9 #>    Plant Type   Treatment  `conc=(-Inf;95;276;457)` `conc=(276;457;638;819)` #>    <ord> <fct>  <fct>                         <dbl>                    <dbl> #>  1 Qn1   Quebec nonchilled                    1                        0     #>  2 Qn1   Quebec nonchilled                    1                        0     #>  3 Qn1   Quebec nonchilled                    1                        0     #>  4 Qn1   Quebec nonchilled                    0.591                    0.409 #>  5 Qn1   Quebec nonchilled                    0                        1     #>  6 Qn1   Quebec nonchilled                    0                        0.796 #>  7 Qn1   Quebec nonchilled                    0                        0     #>  8 Qn2   Quebec nonchilled                    1                        0     #>  9 Qn2   Quebec nonchilled                    1                        0     #> 10 Qn2   Quebec nonchilled                    1                        0     #> # ℹ 74 more rows #> # ℹ 4 more variables: `conc=(638;819;1000;Inf)` <dbl>, #> #   `uptake=(-Inf;7.7;15.3;22.8)` <dbl>, `uptake=(15.3;22.8;30.4;37.9)` <dbl>, #> #   `uptake=(30.4;37.9;45.5;Inf)` <dbl>  # complex transformation with different settings for each column CO2 |>     partition(Plant:Treatment) |>     partition(conc,               .method = \"raisedcos\",               .breaks = c(-Inf, 95, 175, 350, 675, 1000, Inf)) |>     partition(uptake,               .method = \"triangle\",               .breaks = c(-Inf, 7.7, 28.3, 45.5, Inf),               .labels = c(\"low\", \"medium\", \"high\")) #> # A tibble: 84 × 24 #>    `Plant=Qn1` `Plant=Qn2` `Plant=Qn3` `Plant=Qc1` `Plant=Qc3` `Plant=Qc2` #>    <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       <lgl>       #>  1 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #>  2 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #>  3 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #>  4 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #>  5 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #>  6 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #>  7 TRUE        FALSE       FALSE       FALSE       FALSE       FALSE       #>  8 FALSE       TRUE        FALSE       FALSE       FALSE       FALSE       #>  9 FALSE       TRUE        FALSE       FALSE       FALSE       FALSE       #> 10 FALSE       TRUE        FALSE       FALSE       FALSE       FALSE       #> # ℹ 74 more rows #> # ℹ 18 more variables: `Plant=Mn3` <lgl>, `Plant=Mn2` <lgl>, `Plant=Mn1` <lgl>, #> #   `Plant=Mc2` <lgl>, `Plant=Mc3` <lgl>, `Plant=Mc1` <lgl>, #> #   `Type=Quebec` <lgl>, `Type=Mississippi` <lgl>, #> #   `Treatment=nonchilled` <lgl>, `Treatment=chilled` <lgl>, #> #   `conc=(-Inf;95;175)` <dbl>, `conc=(95;175;350)` <dbl>, #> #   `conc=(175;350;675)` <dbl>, `conc=(350;675;1000)` <dbl>, …"},{"path":"https://beerda.github.io/nuggets/reference/remove_almost_constant.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove almost constant columns from a data frame — remove_almost_constant","title":"Remove almost constant columns from a data frame — remove_almost_constant","text":"Function tests columns specified .argument removes almost constant. column considered almost constant proportion frequent value greater threshold specified .threshold argument. See is_almost_constant() details.","code":""},{"path":"https://beerda.github.io/nuggets/reference/remove_almost_constant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove almost constant columns from a data frame — remove_almost_constant","text":"","code":"remove_almost_constant(   .data,   .what = everything(),   ...,   .threshold = 1,   .na_rm = FALSE,   .verbose = FALSE )"},{"path":"https://beerda.github.io/nuggets/reference/remove_almost_constant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove almost constant columns from a data frame — remove_almost_constant","text":".data data frame .tidyselect expression (see tidyselect syntax) selecting columns processed ... optional tidyselect expressions selecting additional columns processed .threshold numeric scalar range \\([0, 1]\\) specifying threshold proportion frequent value .na_rm logical scalar indicating whether remove NA values computing proportion frequent value. See is_almost_constant() details NA values handled. .verbose logical scalar indicating whether print message removed columns","code":""},{"path":"https://beerda.github.io/nuggets/reference/remove_almost_constant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove almost constant columns from a data frame — remove_almost_constant","text":"data frame removed columns specified .argument also (almost) constant","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/remove_almost_constant.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remove almost constant columns from a data frame — remove_almost_constant","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/remove_almost_constant.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove almost constant columns from a data frame — remove_almost_constant","text":"","code":"d <- data.frame(a1 = 1:10,                 a2 = c(1:9, NA),                 b1 = \"b\",                 b2 = NA,                 c1 = rep(c(TRUE, FALSE), 5),                 c2 = rep(c(TRUE, NA), 5),                 d = c(rep(TRUE, 4), rep(FALSE, 4), NA, NA)) remove_almost_constant(d, .threshold = 1.0, .na_rm = FALSE) #> # A tibble: 10 × 5 #>       a1    a2 c1    c2    d     #>    <int> <int> <lgl> <lgl> <lgl> #>  1     1     1 TRUE  TRUE  TRUE  #>  2     2     2 FALSE NA    TRUE  #>  3     3     3 TRUE  TRUE  TRUE  #>  4     4     4 FALSE NA    TRUE  #>  5     5     5 TRUE  TRUE  FALSE #>  6     6     6 FALSE NA    FALSE #>  7     7     7 TRUE  TRUE  FALSE #>  8     8     8 FALSE NA    FALSE #>  9     9     9 TRUE  TRUE  NA    #> 10    10    NA FALSE NA    NA    remove_almost_constant(d, .threshold = 1.0, .na_rm = TRUE) #> # A tibble: 10 × 4 #>       a1    a2 c1    d     #>    <int> <int> <lgl> <lgl> #>  1     1     1 TRUE  TRUE  #>  2     2     2 FALSE TRUE  #>  3     3     3 TRUE  TRUE  #>  4     4     4 FALSE TRUE  #>  5     5     5 TRUE  FALSE #>  6     6     6 FALSE FALSE #>  7     7     7 TRUE  FALSE #>  8     8     8 FALSE FALSE #>  9     9     9 TRUE  NA    #> 10    10    NA FALSE NA    remove_almost_constant(d, .threshold = 0.5, .na_rm = FALSE) #> # A tibble: 10 × 3 #>       a1    a2 d     #>    <int> <int> <lgl> #>  1     1     1 TRUE  #>  2     2     2 TRUE  #>  3     3     3 TRUE  #>  4     4     4 TRUE  #>  5     5     5 FALSE #>  6     6     6 FALSE #>  7     7     7 FALSE #>  8     8     8 FALSE #>  9     9     9 NA    #> 10    10    NA NA    remove_almost_constant(d, .threshold = 0.5, .na_rm = TRUE) #> # A tibble: 10 × 2 #>       a1    a2 #>    <int> <int> #>  1     1     1 #>  2     2     2 #>  3     3     3 #>  4     4     4 #>  5     5     5 #>  6     6     6 #>  7     7     7 #>  8     8     8 #>  9     9     9 #> 10    10    NA remove_almost_constant(d, a1:b2, .threshold = 0.5, .na_rm = TRUE) #> # A tibble: 10 × 5 #>       a1    a2 c1    c2    d     #>    <int> <int> <lgl> <lgl> <lgl> #>  1     1     1 TRUE  TRUE  TRUE  #>  2     2     2 FALSE NA    TRUE  #>  3     3     3 TRUE  TRUE  TRUE  #>  4     4     4 FALSE NA    TRUE  #>  5     5     5 TRUE  TRUE  FALSE #>  6     6     6 FALSE NA    FALSE #>  7     7     7 TRUE  TRUE  FALSE #>  8     8     8 FALSE NA    FALSE #>  9     9     9 TRUE  TRUE  NA    #> 10    10    NA FALSE NA    NA"},{"path":"https://beerda.github.io/nuggets/reference/remove_ill_conditions.html","id":null,"dir":"Reference","previous_headings":"","what":"From a given list remove those elements that are not valid conditions. — remove_ill_conditions","title":"From a given list remove those elements that are not valid conditions. — remove_ill_conditions","text":"valid condition character vector predicates, predicate corresponds column name related data frame. (empty character vector considered valid condition .)","code":""},{"path":"https://beerda.github.io/nuggets/reference/remove_ill_conditions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"From a given list remove those elements that are not valid conditions. — remove_ill_conditions","text":"","code":"remove_ill_conditions(x, data)"},{"path":"https://beerda.github.io/nuggets/reference/remove_ill_conditions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"From a given list remove those elements that are not valid conditions. — remove_ill_conditions","text":"x list character vector data matrix data frame","code":""},{"path":"https://beerda.github.io/nuggets/reference/remove_ill_conditions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"From a given list remove those elements that are not valid conditions. — remove_ill_conditions","text":"list elements x valid conditions.","code":""},{"path":[]},{"path":"https://beerda.github.io/nuggets/reference/remove_ill_conditions.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"From a given list remove those elements that are not valid conditions. — remove_ill_conditions","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a tibble of combinations of selected column names — var_grid","title":"Create a tibble of combinations of selected column names — var_grid","text":"xvars yvars arguments tidyselect expressions (see tidyselect syntax) specify columns x whose names used domain combinations. yvars NULL, function creates tibble one column var enumerating column names specified xvars argument. yvars NULL, function creates tibble two columns, xvar yvar, whose rows enumerate combinations column names specified xvars yvars argument. allowed specify column xvars yvars arguments. case, combinations column removed result. words, function creates grid possible pairs \\((xx, yy)\\) \\(xx \\xvars\\), \\(yy \\yvars\\), \\(xx \\neq yy\\).","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a tibble of combinations of selected column names — var_grid","text":"","code":"var_grid(   x,   xvars = everything(),   yvars = everything(),   allow = \"all\",   xvar_name = if (quo_is_null(enquo(yvars))) \"var\" else \"xvar\",   yvar_name = \"yvar\",   error_context = list(arg_x = \"x\", arg_xvars = \"xvars\", arg_yvars = \"yvars\", arg_allow =     \"allow\", arg_xvar_name = \"xvar_name\", arg_yvar_name = \"yvar_name\", call =     current_env()) )"},{"path":"https://beerda.github.io/nuggets/reference/var_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a tibble of combinations of selected column names — var_grid","text":"x either data frame matrix xvars tidyselect expression (see tidyselect syntax) specifying columns x, whose names used domain combinations use first place (xvar) yvars NULL tidyselect expression (see tidyselect syntax) specifying columns x, whose names used domain combinations use second place (yvar) allow character string specifying columns allowed selected xvars yvars arguments. Possible values : \"\" - columns allowed selected \"numeric\" - numeric columns allowed selected xvar_name name first column resulting tibble. yvar_name name second column resulting tibble. column exist yvars NULL. error_context list details used error messages. argument useful var_grid() called another function provide error messages, refer arguments calling function. list must contain following elements: arg_x - name argument x character string arg_xvars - name argument xvars character string arg_yvars - name argument yvars character string arg_allow - name argument allow character string arg_xvar_name - name xvar column output tibble arg_yvar_name - name yvar column output tibble call - environment evaluate error messages.","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a tibble of combinations of selected column names — var_grid","text":"yvars NULL, function returns tibble single column (var). yvars non-NULL expression, function returns two columns (xvar yvar) rows enumerating combinations column names specified tidyselect expressions xvars yvars arguments.","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_grid.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a tibble of combinations of selected column names — var_grid","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_grid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a tibble of combinations of selected column names — var_grid","text":"","code":"# Create a grid of combinations of all pairs of columns in the CO2 dataset: var_grid(CO2) #> # A tibble: 10 × 2 #>    xvar      yvar      #>    <chr>     <chr>     #>  1 Plant     Type      #>  2 Plant     Treatment #>  3 Plant     conc      #>  4 Plant     uptake    #>  5 Type      Treatment #>  6 Type      conc      #>  7 Type      uptake    #>  8 Treatment conc      #>  9 Treatment uptake    #> 10 conc      uptake     # Create a grid of combinations of all pairs of columns in the CO2 dataset # such that the first, i.e., `xvar` column is `Plant`, `Type`, or # `Treatment`, and the second, i.e., `yvar` column is `conc` or `uptake`: var_grid(CO2, xvars = Plant:Treatment, yvars = conc:uptake) #> # A tibble: 6 × 2 #>   xvar      yvar   #>   <chr>     <chr>  #> 1 Plant     conc   #> 2 Plant     uptake #> 3 Type      conc   #> 4 Type      uptake #> 5 Treatment conc   #> 6 Treatment uptake"},{"path":"https://beerda.github.io/nuggets/reference/var_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract variable names from predicates — var_names","title":"Extract variable names from predicates — var_names","text":"function assumes x vector predicate names, .e., character vector elements compatible pattern <varname>=<value>. function returns <varname> part elements. string correspond pattern <varname>=<value>, .e., equal sign (=) missing string, whole string returned.","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract variable names from predicates — var_names","text":"","code":"var_names(x)"},{"path":"https://beerda.github.io/nuggets/reference/var_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract variable names from predicates — var_names","text":"x character vector predicate names.","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract variable names from predicates — var_names","text":"<varname> part predicate names x.","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_names.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract variable names from predicates — var_names","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/reference/var_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract variable names from predicates — var_names","text":"","code":"var_names(c(\"a=1\", \"a=2\", \"b=x\", \"b=y\")) # returns c(\"a\", \"a\", \"b\", \"b\") #> [1] \"a\" \"a\" \"b\" \"b\""},{"path":"https://beerda.github.io/nuggets/reference/which_antichain.html","id":null,"dir":"Reference","previous_headings":"","what":"Return indices of first elements of the list, which are incomparable with preceding elements. — which_antichain","title":"Return indices of first elements of the list, which are incomparable with preceding elements. — which_antichain","text":"function returns indices elements given list x, incomparable (.e., neither subset superset) preceding element. first element always selected. next element selected incomparable previously selected elements.","code":""},{"path":"https://beerda.github.io/nuggets/reference/which_antichain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return indices of first elements of the list, which are incomparable with preceding elements. — which_antichain","text":"","code":"which_antichain(x, distance = 0)"},{"path":"https://beerda.github.io/nuggets/reference/which_antichain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return indices of first elements of the list, which are incomparable with preceding elements. — which_antichain","text":"x list integerish vectors distance non-negative integer, specifies allowed discrepancy compared sets","code":""},{"path":"https://beerda.github.io/nuggets/reference/which_antichain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return indices of first elements of the list, which are incomparable with preceding elements. — which_antichain","text":"integer vector indices selected (incomparable) elements.","code":""},{"path":"https://beerda.github.io/nuggets/reference/which_antichain.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Return indices of first elements of the list, which are incomparable with preceding elements. — which_antichain","text":"Michal Burda","code":""},{"path":"https://beerda.github.io/nuggets/news/index.html","id":"nuggets-150","dir":"Changelog","previous_headings":"","what":"nuggets 1.5.0","title":"nuggets 1.5.0","text":"released: ??? added is_almost_constant(), remove_almost_constant(), parse_condition(), fire(), is_condition(), remove_ill_conditions() added .span .inc arguments partition() added exclude argument dig() dig_*() functions","code":""},{"path":"https://beerda.github.io/nuggets/news/index.html","id":"nuggets-140","dir":"Changelog","previous_headings":"","what":"nuggets 1.4.0","title":"nuggets 1.4.0","text":"released: 2025-01-08 added var_names(), dig_baseline_contrasts(), dig_complement_contrasts() dig_contrasts() renamed dig_paired_baseline_contrasts() dig_implications() renamed dig_associations() dichotomize() deprecated (use partition() instead) added max_support argument dig() added max_results argument dig() optimized performance dig() added min_conditional_focus_support argument dig() fixed handling NULL returned callback function dig_grid() argument d callback function dig_grid() renamed pd added handling nd argument callback function dig_grid() added max_p_value argument dig_paired_baseline_contrasts() improved error messages added nuggets vignette started using lifecycle pkgdown","code":""},{"path":"https://beerda.github.io/nuggets/news/index.html","id":"nuggets-130","dir":"Changelog","previous_headings":"","what":"nuggets 1.3.0","title":"nuggets 1.3.0","text":"released: 2024-11-13 added is_degree(), dig_contrasts(), partition() implemented fuzzy variant dig_grid() fixed crash mixing logical (crisp) numeric (fuzzy) inputs dig()","code":""},{"path":"https://beerda.github.io/nuggets/news/index.html","id":"nuggets-120","dir":"Changelog","previous_headings":"","what":"nuggets 1.2.0","title":"nuggets 1.2.0","text":"released: 2024-10-11 added var_grid(), dig_grid() added measures argument dig_implications() fixed contingency table arguments computation (pp, pn, np, nn) - previously, computed relative frequencies, now computed counts fixed new-delete-type-mismatch ASAN error caused wrong implementation AlignedAllocator fixed memory leaks","code":""},{"path":"https://beerda.github.io/nuggets/news/index.html","id":"nuggets-110","dir":"Changelog","previous_headings":"","what":"nuggets 1.1.0","title":"nuggets 1.1.0","text":"released: 2024-10-08 added .argument dichotomize() fixed handling xvars, yvars tidy-selectors dig_correlations() added filtering foci support added handling callback function arguments related contingency tables (pp, pn, np, nn arguments)","code":""},{"path":"https://beerda.github.io/nuggets/news/index.html","id":"nuggets-102","dir":"Changelog","previous_headings":"","what":"nuggets 1.0.2","title":"nuggets 1.0.2","text":"released: 2024-01-09 fixed handling arguments min_coverage min_support dig_implications() attempt fix LTO error related run_testthat_tests() - fixed using RC version Rcpp (1.0.11.6)","code":""},{"path":"https://beerda.github.io/nuggets/news/index.html","id":"nuggets-101","dir":"Changelog","previous_headings":"","what":"nuggets 1.0.1","title":"nuggets 1.0.1","text":"released: 2023-11-29 attempt fix tests failing R-devel","code":""},{"path":"https://beerda.github.io/nuggets/news/index.html","id":"nuggets-100","dir":"Changelog","previous_headings":"","what":"nuggets 1.0.0","title":"nuggets 1.0.0","text":"released: 2023-11-28 first version package implemented: dichotomize(), dig(), dig_implications(), dig_correlations(), which_antichain(), format_condition(), is_subset()","code":""}]
